---
###Entrenamiento Random Forest y CART
---
title: "07 - RF y CART"
output: html_document
---

```{r}
source("../origen/config.R")
source("../origen/data_utils.R")
```

##Librerías

```{r}
# Instalar y cargar
knitr::opts_chunk$set(echo = TRUE)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(dplyr, rpart, readr, tibble, purrr, forcats, tidyverse, readr, janitor, skimr, naniar, DataExplorer,
  GGally, ggcorrplot, lubridate, dplyr, tidyr, stringr, stringi, purrr, tibble, here, webshot2, gt, osmdata, sf, tidyverse, here, units, progressr,osmextract, rosm, ggspatial, prettymapr, nngeo, RANN, textclean, spatialsample, blockCV, tidymodels, SuperLearner, nnls, recipes, Xgboost, ranger, glmnet)
```

```{r}
#Bases de datos
#Bases de datos 
train_final <- readRDS(here::here("data", "processed", "train_final.rds"))
test_final  <- readRDS(here::here("data", "processed", "test_final.rds"))

# Copias originales
train_original <- train_final
test_original  <- test_final

# Asignar datasets de trabajo para el pipeline
train <- train_final
test  <- test_final


```


```{r}
# RF Y CART
target <- if ("price" %in% names(train)) "price" else stop("No encuentro 'price' en train.") 
id_col <- if ("property_id" %in% names(train)) "property_id" else NULL
# Forzar factores planificados
fac_cols <- intersect(c("month","year","localidad","estrato"), names(train))
train <- train %>% mutate(across(all_of(fac_cols), ~as.factor(.)))
test <- test %>% mutate(across(all_of(fac_cols), ~as.factor(.))) 
# Alinear niveles de factores entre train y test
align_levels <- function(tr, te, cols)
  { for (c in cols) { 
    lvls <- union(levels(tr[[c]]), levels(te[[c]])) 
tr[[c]] <- factor(tr[[c]], levels = lvls) 
te[[c]] <- factor(te[[c]], levels = lvls) } 
  list(train=tr, test=te) }
tmp <- align_levels(train, test, fac_cols) 
train <- tmp$train; test <- tmp$test 
# codificar dummies
binary_vars <- intersect(c( "has_parqueadero_garaje","has_seguridad","has_ascensor","has_gimnasio","has_piscina", "has_bbq","has_zona_infantil","has_balcon","has_terraza","has_patio", "has_jardin_exterior","has_chimenea","has_cocina_integral","has_deposito", "has_estudio","has_remodelado","has_vista" ), names(train))

to01 <- function(x)
  { if (is.factor(x))
    x <- as.character(x)
  if (is.character(x)) 
    { x <- tolower(trimws(x)) 
    return(as.integer(x %in% c("1","si","sí","true","t","y","yes","s","present","presente"))) }

if (is.logical(x)) return(as.integer(x)) 
if (is.numeric(x)) return(as.integer(ifelse(is.na(x), NA, x != 0)))
return(as.integer(!is.na(x) & x != 0)) } 

train <- train %>% mutate(across(all_of(binary_vars), to01)) 
test <- test %>% mutate(across(all_of(binary_vars), to01))
# Reemplazar NA en dummies por 0 
train <- train %>% mutate(across(all_of(binary_vars), ~replace_na(., 0L)))
test <- test %>% mutate(across(all_of(binary_vars), ~replace_na(., 0L))) 
# Remover columnas indeseadas si existen
vars_remove <- intersect(c("has_pisos_vivienda","has_salon_social"), names(train)) 
train <- train %>% select(-all_of(vars_remove))
test <- test %>% select(-all_of(vars_remove)) 
# Remover texto crudo 
txt_to_rm <- intersect(c("title","description"), names(train))
train <- train %>% select(-all_of(txt_to_rm)) 
test <- test %>% select(-all_of(txt_to_rm))
# Eliminar columnas de varianza cero 
rec_zv <- recipe(as.formula(paste(target, "~ .")), data = train) %>% update_role(any_of(id_col), new_role = "id") %>% step_zv(all_predictors())
rec_zv_prep <- prep(rec_zv, training = train, verbose = FALSE)
train_nzv <- bake(rec_zv_prep, new_data = NULL) 
test_nzv <- bake(rec_zv_prep, new_data = test) 
# Imputación ligera de NAs residuales
rec_imp <- recipe(as.formula(paste(target, "~ .")), data = train_nzv) %>% update_role(any_of(id_col), new_role = "id") %>% step_impute_median(all_numeric_predictors()) %>% step_impute_mode(all_nominal_predictors()) 
rec_imp_prep <- prep(rec_imp, training = train_nzv, verbose = FALSE) 
train_ready <- bake(rec_imp_prep, new_data = NULL)
test_ready <- bake(rec_imp_prep, new_data = test_nzv)


```


```{r}
# CART Y RF CON CROSS VALIDATION
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(dplyr, rsample, rpart, ranger, purrr, tibble, readr, rlang)

set.seed(2025)
stopifnot(exists("train_ready"), exists("test_ready"))

tgt <- "price"

# TRATAMIENTO
id_candidates <- c("property_id","id")
id_name <- intersect(id_candidates, union(names(train_ready), names(test_ready)))
id_name <- if (length(id_name)) id_name[[1]] else "id"
id_vals <- if (id_name %in% names(test_ready)) as.character(test_ready[[id_name]]) else seq_len(nrow(test_ready))

# CALCULAR MAE
MAE <- function(y, yhat) mean(abs(y - yhat), na.rm = TRUE)
drop_id <- function(df) dplyr::select(df, -dplyr::any_of(id_candidates))
X  <- drop_id(train_ready)
Xt <- drop_id(test_ready)

# MODELOS
fit_cart_1se <- function(df){
  form <- as.formula(paste(tgt, "~ ."))
  ctrl <- rpart::rpart.control(cp = 0.001, minsplit = 20, maxdepth = 12, xval = 10)
  raw  <- rpart::rpart(form, data = df, method = "anova", control = ctrl)
  cpt  <- raw$cptable
  i_min <- which.min(cpt[, "xerror"])
  cp_opt <- cpt[max(which(cpt[, "xerror"] <= cpt[i_min,"xerror"] + cpt[i_min,"xstd"])),"CP"]
  if (is.na(cp_opt)) cp_opt <- cpt[i_min,"CP"]
  rpart::prune(raw, cp = cp_opt)
}
pred_cart <- function(mod, newdata) predict(mod, newdata = newdata)

fit_rf <- function(df){
  p <- ncol(df) - 1L
  ranger::ranger(
    as.formula(paste(tgt, "~ .")), data = df,
    num.trees = 1000, mtry = max(2L, floor(sqrt(p))),
    min.node.size = 10, sample.fraction = 0.80,
    importance = "impurity", seed = 2025
  )
}
pred_rf <- function(mod, newdata) predict(mod, data = newdata)$predictions

# CV estándar
v <- 5
v_regular <- rsample::vfold_cv(X, v = v)

mae_cart_reg <- purrr::map_dbl(v_regular$splits, function(s){
  tr <- rsample::analysis(s); va <- rsample::assessment(s)
  fit <- fit_cart_1se(tr); prd <- pred_cart(fit, va); MAE(va[[tgt]], prd)
})
mae_rf_reg <- purrr::map_dbl(v_regular$splits, function(s){
  tr <- rsample::analysis(s); va <- rsample::assessment(s)
  fit <- fit_rf(tr); prd <- pred_rf(fit, va); MAE(va[[tgt]], prd)
})

# CART
cart_full <- fit_cart_1se(X)
pred_cart_test <- pmax(pred_cart(cart_full, Xt), 0)
readr::write_csv(tibble(!!id_name := id_vals, price = round(pred_cart_test)),
                 "CART_12_20_0.001.csv")

# RF CV ESTANDAR
rf_full <- fit_rf(X)
pred_rf_test <- pmax(pred_rf(rf_full, Xt), 0)
readr::write_csv(tibble(!!id_name := id_vals, price = round(pred_rf_test)),
                 "RF_1000_10_0.8.csv")

# RF CV ESPACIAL
group_col <- dplyr::case_when(
  "dist_parques"          %in% names(train_ready) ~ "dist_parques",
  "dist_colegios" %in% names(train_ready) ~ "dist_colegios",
  "dist_restaurantes"    %in% names(train_ready) ~ "dist_restaurantes",
  "dist_autopistas"    %in% names(train_ready) ~ "dist_autopistas",
  "dist_centros_comerciales"    %in% names(train_ready) ~ "dist_centros_comerciales",
  TRUE ~ NA_character_
)

v_spatial <- rsample::group_vfold_cv(X, v = v, group = !!rlang::sym(group_col))

mae_rf_sp <- purrr::map_dbl(v_spatial$splits, function(s){
  tr <- rsample::analysis(s); va <- rsample::assessment(s)
  fit <- fit_rf(tr); prd <- pred_rf(fit, va); MAE(va[[tgt]], prd)
})
pred_mat <- matrix(NA_real_, nrow = nrow(Xt), ncol = length(v_spatial$splits))
for (k in seq_along(v_spatial$splits)) {
  tr <- rsample::analysis(v_spatial$splits[[k]])
  fit <- fit_rf(tr)
  pred_mat[, k] <- pred_rf(fit, Xt)
}
pred_rf_sp_test <- pmax(rowMeans(pred_mat, na.rm = TRUE), 0)
readr::write_csv(tibble(!!id_name := id_vals, price = round(pred_rf_sp_test)),
                 "RF_CV_espacial.csv")


```


```{r}

# GRAFICO DE IMPORTANCIA DE VARIABLES (RANDOM FOREST ESPACIAL)


library(ggplot2)
library(ranger)
library(dplyr)
library(purrr)
library(tibble)



# Lista para guardar importancia por fold
imp_list <- list()

for (k in seq_along(v_spatial$splits)) {
  tr <- rsample::analysis(v_spatial$splits[[k]])

  fit_k <- fit_rf(tr)  # usa tu función fit_rf()

  imp_list[[k]] <- ranger::importance(fit_k)
}

# Convertir lista en matriz
imp_mat <- do.call(cbind, imp_list)

# Promedio de importancia por variable
imp_mean <- rowMeans(imp_mat, na.rm = TRUE)

# Ordenar de mayor a menor
imp_rank <- sort(imp_mean, decreasing = TRUE)

# Tibble para gráfico
imp_tbl <- tibble(
  variable = names(imp_rank),
  importance = imp_rank
)

# Gráfico: Top 10 variables

# Normalizar importancia para que estén en escala 0–1
imp_tbl_norm <- imp_tbl %>%
  mutate(importance_scaled = importance / max(importance))

top_n <- 10
imp_top <- imp_tbl_norm %>% slice_max(order_by = importance_scaled, n = top_n)

imp_variables <- ggplot(imp_top, aes(x = reorder(variable, importance_scaled), y = importance_scaled)) +
   geom_col(fill = "gray60", width = 0.65) +
  geom_text(aes(label = round(importance_scaled, 3)),
            hjust = -0.15, size = 4, color = "gray20") +
  coord_flip(clip = "off") +
  labs(
    title = "Importancia de Variables",
    x = "Variable",
    y = "Importancia normalizada"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(size = 20, face = "bold"),
    plot.subtitle = element_text(size = 13),
    axis.title.x = element_text(size = 15),
    axis.title.y = element_text(size = 15),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    panel.grid.major.y = element_blank(),
    plot.margin = grid::unit(c(20, 30, 20, 20), "pt")
  ) +
  expand_limits(y = 1.15 * max(imp_top$importance_scaled))

imp_variables
#Directorio
root_dir <- here::here()

# Crea subrutas relativas al proyecto
path_outputs <- file.path(root_dir, "outputs")
path_figures <- file.path(path_outputs, "figures")
 
#  Guardar
dir.create("outputs/figures", recursive = TRUE, showWarnings = FALSE)
ggsave("outputs/figures/importancia_variables.png", imp_variables, width = 8, height = 6, dpi = 300)

```