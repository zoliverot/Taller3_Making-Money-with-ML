
---
title: "Problem Set 3 - BDML"
author: "Cristian Mu√±oz - Vivian Cabanzo - Zeneth Olivero - Laura Diaz"
date: "2025-11-23"
output: html_document
---

# 1. DATOS. 

##Librer√≠as

```{r setup, include=FALSE}

# Instalar y cargar pacman (gestor de paquetes)
knitr::opts_chunk$set(echo = TRUE)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
  tidyverse, readr, janitor, skimr, naniar, DataExplorer,
  GGally, ggcorrplot, lubridate, dplyr, tidyr, stringr, stringi, purrr, tibble, here
)

# Verificar paquetes cargados
pacman::p_loaded()
```


## Cargar de bases de datos
```{r}
#Base de datos test
test <- read_csv("https://raw.githubusercontent.com/cristianmu910/datos-taller-3/main/test.csv")
##Base de datos train
train <- read_csv("https://raw.githubusercontent.com/cristianmu910/datos-taller-3/main/train.csv")
```


## Limpieza de datos

```{r}
#Configuraci√≥n inicial

#Establecemos visuales minimalistas
theme_set(theme_minimal())

# Normalizar nombres a snake_case
train <- janitor::clean_names(train)
test  <- janitor::clean_names(test)

# Objetivo a predecir
target <- "price"

```


```{r}

# Estructura y diferencias b√°sicas entre train y test

#diferencias y similutes
cat("\nDimensiones:\n")
cat("train: ", paste(dim(train), collapse=" x "), "\n") #38644 observaciones
cat("test : ", paste(dim(test),  collapse=" x "), "\n") #10286 observaciones
#Tienen las misma cantidad de variables

#Reviamos nombres
train_cols <- names(train)
test_cols  <- names(test)

#Diferencia en variables
cols_common        <- intersect(train_cols, test_cols)
cols_train_only    <- setdiff(train_cols, test_cols)
cols_test_only     <- setdiff(test_cols, train_cols)
cols_common_nontgt <- setdiff(cols_common, target)

cat("\nColumnas SOLO en train (excluyendo target):\n")
print(setdiff(cols_train_only, target))
cat("\nColumnas SOLO en test:\n")
print(cols_test_only)
#Todas las columnas son comunes

cat("\nPrimeras columnas comunes:\n")
print(head(cols_common, 20))


# Tipos de datos y vistazo

cat("\nGlimpse train:\n")
glimpse(train)
cat("\nGlimpse test:\n")
glimpse(test)
#Pice vacio en test

# Resumen estad√≠stico b√°sico de train
cat("\nResumen SKIM (train):\n")
skimr::skim(train)

#6 variables caracter
#10 variables numericas
#Faltantes en m2 total, m2 cubierta, cuartos y ba√±os.

str(train)
```


## Revisamos duplicados 

```{r}

# Duplicados en ID
id_col <- dplyr::case_when(
  "property_id" %in% names(train) ~ "property_id",
  TRUE ~ NA_character_
)

if (!is.na(id_col)) {
  dup_train <- train %>% count(.data[[id_col]]) %>% filter(n > 1) %>% nrow()
  dup_test  <- test  %>% count(.data[[id_col]]) %>% filter(n > 1) %>% nrow()
  cat("\nDuplicados por ID en train:", dup_train, " | en test:", dup_test, "\n")
} else {
  cat("\n(No hay duplicados)\n")
  cat("Filas duplicadas en train:", sum(duplicated(train)), "\n")
  cat("Filas duplicadas en test :", sum(duplicated(test)),  "\n")
}

getwd()
```
#Revis√≥n exaustiva de Na
```{r}


# Calcular % de faltantes en TRAIN hogares
faltantes_train <- train %>%
  summarise(across(everything(), ~mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Porcentaje_NA") %>%
  mutate(Base = "Entrenamiento")

# Calcular % de faltantes en TEST hogares
faltantes_test <- test %>%
  summarise(across(everything(), ~mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Porcentaje_NA") %>%
  mutate(Base = "Prueba")

# Unir ambas bases
faltantes_comp <- bind_rows(faltantes_train, faltantes_test)


# Gr√°fico comparativo con leyenda inferior
grafico_faltantes <- ggplot(faltantes_comp, aes(x = Variable, y = Porcentaje_NA, fill = Base)) +
  geom_bar(stat = "identity", position = "dodge", color = "gray30") +
  geom_text(
    aes(label = paste0(round(Porcentaje_NA, 2), "%")),
    position = position_dodge(width = 0.9),
    vjust = -0.3, size = 3
  ) +
  coord_flip() +
  labs(
    title = "Comparaci√≥n de % de valores faltantes por variable\nTrain vs Test",
    x = "Variable",
    y = "% de valores faltantes",
    fill = "Base de datos"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    legend.position = "bottom",              # üîπ Mueve la leyenda abajo
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 10),
    axis.text.y = element_text(size = 9),
    axis.text.x = element_text(size = 9),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank()
  ) +
  scale_fill_manual(
    values = c("Entrenamiento" = "lightyellow4", "Prueba" = "#FFFF00")
  )



#Gardar Gr√°fica

root_dir <- here::here()

# Crea subrutas relativas al proyecto
path_outputs <- file.path(root_dir, "outputs")
path_figures <- file.path(path_outputs, "figures")

#PDF
ggsave(
  filename = file.path(path_figures, "Faltantes_Trains.pdf"),
  plot = grafico_faltantes,
  width = 10, height = 6
)

#PNG
ggsave(
  filename = file.path(path_figures, "Faltantes_Trains.png"),
  plot = grafico_faltantes,
  width = 10, height = 6,
  dpi = 300
)

# Mostrar en pantalla
print(grafico_faltantes)



```
## Revisi√≥n outliers

```{r}

# Seleccionar variables num√©rica
vars_outliers <- train %>%
  select(where(is.numeric)) %>%
  select(-any_of(c("price", "year", "lon", "lat", "month")))

#‚É£ Pasar a formato largo
vars_long <- vars_outliers %>%
  pivot_longer(cols = everything(),
               names_to = "Variable",
               values_to = "Valor")

#  Graficar boxplots 
grafico_outliers <- ggplot(vars_long, aes(x = Variable, y = Valor)) +
  geom_boxplot(fill = "#87CEFA", color = "gray30", outlier.colour = "red", alpha = 0.6, width = 0.6) +
  coord_flip() +
  labs(
    title = "Detecci√≥n de outliers",
    x = "Variable",
    y = "Valor"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 15),
    axis.title.x = element_text(size = 12, margin = margin(t = 10)),
    axis.title.y = element_text(size = 12, margin = margin(r = 10)),
    axis.text.y = element_text(size = 11),
    axis.text.x = element_text(size = 10),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank()
  )


print(grafico_outliers)

#Gurdamos gr√°fica

# Ruta din√°mica
root_dir <- here::here()
path_outputs <- file.path(root_dir, "outputs")
path_figures <- file.path(path_outputs, "figures")
dir.create(path_figures, recursive = TRUE, showWarnings = FALSE)


#PDF
ggsave(
  filename = file.path(path_figures, "Outliers.pdf"),
  plot = grafico_outliers,
  width = 9, height = 12, dpi = 300
)
#PNG
ggsave(
  filename = file.path(path_figures, "Outliers.png"),
  plot = grafico_outliers,
  width = 9, height = 12, dpi = 300
)

#Revismos si hay observaciones donde el cubierto sea mayor que el total
train %>%
  filter(surface_covered > surface_total) %>%
  select(surface_total, surface_covered)
```


```{r}

# Detectar num√©ricas vs categ√≥ricas

numericas <- function(x) is.numeric(x) || inherits(x, c("integer","numeric","double"))
num_cols <- train %>%
  select(any_of(cols_common_nontgt)) %>%
  select(where(numericas)) %>% names()

cat_cols <- setdiff(cols_common_nontgt, num_cols)

cat("\nNum√©ricas:\n"); print(num_cols)
cat("\nCateg√≥ricas:\n"); print(cat_cols)

# ===============================
# 7) Distribuciones (gr√°ficos sencillos)
# ===============================

# 7.1 Histograma para cada num√©rica (train)
if (length(num_cols) > 0) {
  train %>%
    select(all_of(num_cols)) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "valor") %>%
    ggplot(aes(x = valor)) +
    geom_histogram(bins = 30) +
    facet_wrap(~ variable, scales = "free", ncol = 3) +
    labs(title = "Histogramas (TRAIN)", x = NULL, y = "Frecuencia")
}

# 7.2 Densidad del target (train), si existe
if (target %in% names(train)) {
  # Densidad en escala original
  ggplot(train, aes(x = .data[[target]])) +
    geom_density() +
    labs(title = paste("Densidad de", target, "(TRAIN)"), x = target, y = "Densidad")

  # Densidad en log (opcional)
  if (all(is.finite(train[[target]]), na.rm = TRUE)) {
    ggplot(train %>% filter(.data[[target]] > 0), aes(x = log1p(.data[[target]]))) +
      geom_density() +
      labs(title = paste("Densidad de log1p(", target, ") (TRAIN)"), x = paste0("log1p(", target, ")"), y = "Densidad")
  }
}

# 7.3 Boxplots del target por algunas categ√≥ricas (top k categor√≠as m√°s frecuentes)
top_k_levels <- function(x, k = 12) {
  forcats::fct_lump_n(x, n = k, other_level = "otros")
}

if (target %in% names(train) && length(cat_cols) > 0) {
  for (cc in cat_cols) {
    p <- train %>%
      mutate(..grp = top_k_levels(.data[[cc]], k = 12)) %>%
      ggplot(aes(x = ..grp, y = .data[[target]])) +
      geom_boxplot(outlier.alpha = 0.2) +
      coord_flip() +
      labs(title = paste("Boxplot de", target, "por", cc, "(TRAIN)"),
           x = cc, y = target)
    print(p)
  }
}

# 7.4 Pares de variables (scatter) para algunas num√©ricas clave
pairs_cols <- intersect(num_cols, c("bathrooms","bedrooms","rooms","surface_total","surface_covered","lat","lon","year","month"))
if (length(pairs_cols) >= 2 && target %in% names(train)) {
  df_pairs <- train %>% select(all_of(pairs_cols), all_of(target)) %>% drop_na()
  GGally::ggpairs(df_pairs, columns = 1:length(pairs_cols),
                  title = "Matriz de pares (subset num√©rico) - TRAIN")
}

# ===============================
# 8) Correlaciones num√©ricas
# ===============================
if (length(num_cols) >= 2) {
  # correlaciones entre num√©ricas (train)
  cormat <- train %>% select(all_of(num_cols)) %>%
    mutate(across(everything(), as.numeric)) %>%
    cor(use = "pairwise.complete.obs")

  ggcorrplot::ggcorrplot(cormat, lab = FALSE, type = "lower") +
    ggtitle("Correlaci√≥n entre variables num√©ricas (TRAIN)")

  # correlaci√≥n con target si num√©rico
  if (target %in% names(train) && is.numeric(train[[target]])) {
    cor_with_target <- train %>%
      select(all_of(num_cols), all_of(target)) %>%
      cor(use = "pairwise.complete.obs") %>%
      as.data.frame() %>%
      rownames_to_column("variable") %>%
      select(variable, all_of(target)) %>%
      arrange(desc(abs(.data[[target]])))
    cat("\nCorrelaci√≥n con el target (TRAIN):\n")
    print(cor_with_target)
  }
}

# ===============================
# 9) Recomendaci√≥n de columnas a modelar
# ===============================
keep_features <- setdiff(cols_common, target)  # lo com√∫n menos la y
cat("\nFeatures a usar (comunes, sin target):\n")
print(keep_features)
```
# An√°lisis de texto
```{r}
# --- 1) Normalizador de texto (lower + sin tildes + espacios compactados) ---
normalize_text <- function(x) {
  x %>%
    tidyr::replace_na("") %>%
    stringi::stri_trans_general("Latin-ASCII") %>% # quita tildes
    tolower() %>%
    stringr::str_squish()
}

# --- 2) Diccionario de atributos (regex) para dummies desde title+description ---
# Puedes ajustar/expandir vocabulario seg√∫n tu mercado
attr_patterns <- list(
  ubic_parque          = "\\bparques?\\b(?!adero)",                             # parque, no parqueadero
  parqueadero_garaje   = "\\b(parqueadero|garaje|estacionamiento)s?\\b",
  transporte_metro_tm  = "\\b(metro|transmilenio|sitp|subte|estacion|paradero)\\b",
  colegio_universidad  = "\\b(colegios?|universidades?|jardin(?:es)? infantil(?:es)?)\\b",
  salud_hospital       = "\\b(hospital(es)?|clinica(s)?|centro(s)? medico(s)?)\\b",
  centro_comercial     = "\\b(centro(s)? comercial(es)?)\\b",
  supermercado         = "\\b(supermercado(s)?|tienda(s)?|exito|carulla|jumbo|olimpica|d1|ara)\\b",
  seguridad            = "\\b(vigilancia|porteri[ai]|seguridad|camaras?)\\b",
  amenities            = "\\b(piscina|gimnasio|bbq|sal[o√≥]n social|zona social|zona infantil)\\b",
  ascensor             = "\\bascensor(es)?\\b",
  balcon               = "\\bbalcon(es)?\\b",
  terraza              = "\\bterraza(s)?\\b",
  remodelado           = "\\b(remodelad[oa]s?|remodelaci[o√≥]n)\\b",
  cocina_integral      = "\\bcocina integral\\b",
  iluminacion          = "\\biluminaci[o√≥]n\\b",
  ventilacion          = "\\bventilaci[o√≥]n\\b",
  patio                = "\\bpatio(s)?\\b",
  estudio              = "\\bestudio(s)?\\b",
  deposito             = "\\bdepo[si]t[o√≥]s?\\b|\\bbaulera(s)?\\b|\\btrastero(s)?\\b",
  chimenea             = "\\bchimenea(s)?\\b",
  walk_in_closet       = "\\b(vestier|walk(?:-|\\s*)in\\s*closet)\\b",
  vista                = "\\b(vista|panor[a√°]mica)\\b",
  exterior_interior    = "\\b(exterior|interior|esquinero|esquina)\\b",
  estrato              = "\\bestrato\\s*[1-6]\\b"
)

# --- 3) Funci√≥n: construir dummies desde texto ---
add_text_flags <- function(df, patterns = attr_patterns) {
  stopifnot(all(c("title","description") %in% names(df)))
  txt <- normalize_text(paste(df$title, df$description))
  out <- df
  for (nm in names(patterns)) {
    rx <- stringr::regex(patterns[[nm]], ignore_case = TRUE)
    out[[paste0("has_", nm)]] <- as.integer(stringr::str_detect(txt, rx))
  }
  out
}

# --- 4) Aplica procesamiento a train/test ---
train_txt <- add_text_flags(train)
test_txt  <- add_text_flags(test)

# --- 5) Evaluaci√≥n univariada vs price en TRAIN (cobertura, efecto, %Œî, eta¬≤) ---
target <- "price"

score_one_attr <- function(df, attr_col, target = "price") {
  # grupos por flag
  g <- df |>
    dplyr::summarise(
      mean1 = mean(.data[[target]][.data[[attr_col]] == 1], na.rm = TRUE),
      mean0 = mean(.data[[target]][.data[[attr_col]] == 0], na.rm = TRUE),
      n1    = sum(.data[[attr_col]] == 1, na.rm = TRUE),
      n0    = sum(.data[[attr_col]] == 0, na.rm = TRUE),
      .groups = "drop"
    )
  effect   <- g$mean1 - g$mean0
  pct_diff <- ifelse(is.finite(g$mean0) && g$mean0 != 0, effect / g$mean0, NA_real_)
  # eta¬≤ (varianza explicada por 2 grupos)
  grand    <- mean(df[[target]], na.rm = TRUE)
  ss_between <- g$n1 * (g$mean1 - grand)^2 + g$n0 * (g$mean0 - grand)^2
  ss_total   <- sum((df[[target]] - grand)^2, na.rm = TRUE)
  eta2 <- ifelse(ss_total > 0, ss_between / ss_total, 0)
  tibble(
    attribute = attr_col,
    support_1 = g$n1,
    rate_1    = (g$n1)/(g$n1 + g$n0),
    mean_price_1 = g$mean1,
    mean_price_0 = g$mean0,
    mean_diff    = effect,
    pct_diff     = pct_diff,
    eta2         = eta2
  )
}

flag_cols <- names(train_txt) |> (\(v) v[stringr::str_starts(v, "has_")])()
stats_tbl <- purrr::map_dfr(flag_cols, ~score_one_attr(train_txt, .x, target = target))

# Ranking: cobertura m√≠nima, tama√±o de efecto y eta¬≤ (ajusta pesos si quieres)
min_rate <- 0.03  # >= 3% de menciones
ranked <- stats_tbl |>
  mutate(rank_score = eta2 * 0.5 + abs(pct_diff) * 0.3 + rate_1 * 0.2) |>
  filter(rate_1 >= min_rate) |>
  arrange(desc(rank_score))

# --- 6) Reducir redundancia entre dummies (phi) y elegir TOP-4 ---
phi_bin <- function(a, b) {
  pa <- mean(a); pb <- mean(b)
  cov <- mean(a*b) - pa*pb
  denom <- sqrt(pa*(1-pa)*pb*(1-pb))
  if (!is.finite(denom) || denom == 0) return(0)
  cov/denom
}

# matriz phi en candidatas
cand <- ranked$attribute
Phi <- matrix(NA_real_, nrow = length(cand), ncol = length(cand), dimnames = list(cand, cand))
for (i in seq_along(cand)) {
  for (j in seq_along(cand)) {
    if (i == j) { Phi[i, j] <- 1; next }
    a <- as.integer(train_txt[[cand[i]]]); b <- as.integer(train_txt[[cand[j]]])
    Phi[i, j] <- phi_bin(a, b)
  }
}

picked <- character(0)
for (nm in ranked$attribute) {
  if (length(picked) == 4) break
  ok <- all(abs(Phi[nm, picked, drop = FALSE]) <= 0.8)
  if (ok) picked <- c(picked, nm)
}

top4 <- picked
top4
#> vector con los 4 "has_*" seleccionados autom√°ticamente

# --- 7) Crear SOLO esas 4 dummies finales coherentes en train/test ---
add_top4 <- function(df, final_names) {
  # Asegura columnas aunque alguna no aparezca en test
  for (nm in final_names) if (!nm %in% names(df)) df[[nm]] <- 0L
  df |>
    mutate(across(all_of(final_names), ~as.integer(.))) 
}

train_ready <- add_top4(train_txt, top4)
test_ready  <- add_top4(test_txt,  top4)

# --- 8) Peque√±as tablas para el informe (justificaci√≥n reproducible) ---
justificacion <- ranked |>
  filter(attribute %in% top4) |>
  select(attribute, support_1, rate_1, mean_price_1, mean_price_0, mean_diff, pct_diff, eta2, rank_score)

justificacion |>
  arrange(desc(rank_score)) |>
  mutate(pct_diff = scales::percent(pct_diff, accuracy = 0.1),
         rate_1   = scales::percent(rate_1, accuracy = 0.1)) |>
  select(attribute, rate_1, mean_price_1, mean_price_0, pct_diff, eta2)

```


# Variables Internas (4 variables que salen de la columna de texto en ambas bases de datos)
```{r}

# Normaliza: min√∫sculas, sin tildes, espacios compactados
normalize_text <- function(x) {
  x %>%
    tidyr::replace_na("") %>%
    stringi::stri_trans_general("Latin-ASCII") %>%
    tolower() %>%
    stringr::str_squish()
}

# Crea las 4 dummies desde title + description
add_text_dummies <- function(df) {
  stopifnot(all(c("title","description") %in% names(df)))
  
  txt <- normalize_text(paste(df$title, df$description))
  
  # Patrones (regex) ‚Äî puedes ajustar si quieres ampliar vocabulario
  rx_parqueadero_garaje <- stringr::regex("\\b(parqueadero|garaje|estacionamiento)s?\\b", ignore_case = TRUE)
  rx_cocina_integral    <- stringr::regex("\\bcocina integral\\b", ignore_case = TRUE)
  rx_estudio            <- stringr::regex("\\bestudio(s)?\\b", ignore_case = TRUE)
  rx_chimenea           <- stringr::regex("\\bchimenea(s)?\\b", ignore_case = TRUE)
  
  df %>%
    mutate(
      has_parqueadero_garaje = as.integer(stringr::str_detect(txt, rx_parqueadero_garaje)),
      has_cocina_integral    = as.integer(stringr::str_detect(txt, rx_cocina_integral)),
      has_estudio            = as.integer(stringr::str_detect(txt, rx_estudio)),
      has_chimenea           = as.integer(stringr::str_detect(txt, rx_chimenea))
    )
}

# === Uso ===
# train ya cargado como data.frame/tibble con columnas title y description
train_ready <- add_text_dummies(train)
test_ready <- add_text_dummies(test)

# (Opcional) ver cobertura de cada dummie en train
colMeans(dplyr::select(train_ready, starts_with("has_")))
colMeans(dplyr::select(test_ready, starts_with("has_")))

```

