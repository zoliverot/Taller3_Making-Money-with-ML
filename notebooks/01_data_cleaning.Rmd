
---
title: "Problem Set 3 - BDML"
author: "Cristian Mu√±oz - Vivian Cabanzo - Zeneth Olivero - Laura Diaz"
date: "2025-11-23"
output: html_document
---

# 1. DATOS. 

##Librer√≠as

```{r setup, include=FALSE}

# Instalar y cargar pacman (gestor de paquetes)
knitr::opts_chunk$set(echo = TRUE)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
  tidyverse, readr, janitor, skimr, naniar, DataExplorer,
  GGally, ggcorrplot, lubridate, dplyr, tidyr, stringr, stringi, purrr, tibble, here, webshot2, gt, osmdata, sf, tidyverse, here, units, progressr,osmextract, rosm, ggspatial, prettymapr
)



# Verificar paquetes cargados
pacman::p_loaded()
```


## Cargar de bases de datos
```{r}
#Base de datos test
test <- read_csv("https://raw.githubusercontent.com/cristianmu910/datos-taller-3/main/test.csv")
##Base de datos train
train <- read_csv("https://raw.githubusercontent.com/cristianmu910/datos-taller-3/main/train.csv")
```


## Limpieza de datos

```{r}
#Configuraci√≥n inicial

#Establecemos visuales minimalistas
theme_set(theme_minimal())

# Normalizar nombres a snake_case
train <- janitor::clean_names(train)
test  <- janitor::clean_names(test)

# Objetivo a predecir
target <- "price"

```


```{r}

# Estructura y diferencias b√°sicas entre train y test

#diferencias y similutes
cat("\nDimensiones:\n")
cat("train: ", paste(dim(train), collapse=" x "), "\n") #38644 observaciones
cat("test : ", paste(dim(test),  collapse=" x "), "\n") #10286 observaciones
#Tienen las misma cantidad de variables

#Reviamos nombres
train_cols <- names(train)
test_cols  <- names(test)

#Diferencia en variables
vars_comunes <- intersect(names(train), names(test))
vars_train   <- setdiff(names(train), names(test))
vars_test    <- setdiff(names(test), names(train))
# Variables exclusivas en test (texto)
solo_test <- if (length(vars_test) == 0) "Ninguna variable" else paste(vars_test, collapse = ", ")

#  Construir tabla resumen
comp_bd_prop <- tibble(
  Categoria = c("En ambos datasets", "Solo en train", "Solo en test"),
  Cantidad  = c(length(vars_comunes), length(vars_train), length(vars_test)),
  Variables = c(
    paste(vars_comunes, collapse = ", "),
    ifelse(length(vars_train) == 0, "Ninguna variable", paste(vars_train, collapse = ", ")),
    solo_test
  )
)


# Formatear tabla con gt
tabla_comp_prop <- comp_bd_prop %>%
  gt() %>%
  tab_header(
    title = md("**Resumen de Variables entre la muestra de entrenamiento y de prueba (Propiedades)**")
  ) %>%
  cols_label(
    Categoria = "Categor√≠a",
    Cantidad = "N¬∞ de Variables",
    Variables = "Variables"
  ) %>%
  tab_options(
    table.font.size = 12,
    table.align = "left",
    heading.align = "center"
  )

#Gurdamos y exportamos

root_dir <- here::here()
path_outputs <- file.path(root_dir, "outputs")
path_tables <- file.path(path_outputs, "Tablas_y_Graficos")

dir.create(path_outputs, showWarnings = FALSE)
dir.create(path_tables, showWarnings = FALSE)

#  Exportar tabla en HTML, PDF y PNG
html_path <- file.path(path_tables, "Comparacion_bases_propiedades.html")
pdf_path  <- file.path(path_tables, "Comparacion_bases_propiedades.pdf")
png_path  <- file.path(path_tables, "Comparacion_bases_propiedades.png")

gtsave(tabla_comp_prop, html_path)
webshot2::webshot(html_path, pdf_path)
webshot2::webshot(html_path, png_path)

#Resumen tabla
tabla_comp_prop



# Tipos de datos y vistazo

cat("\nGlimpse train:\n")
glimpse(train)
cat("\nGlimpse test:\n")
glimpse(test)
#Pice vacio en test

# Resumen estad√≠stico b√°sico de train
cat("\nResumen SKIM (train):\n")
skimr::skim(train)

#6 variables caracter
#10 variables numericas
#Faltantes en m2 total, m2 cubierta, cuartos y ba√±os.

str(train)
```


## Revisamos duplicados 

```{r}

# Duplicados en ID
id_col <- dplyr::case_when(
  "property_id" %in% names(train) ~ "property_id",
  TRUE ~ NA_character_
)

if (!is.na(id_col)) {
  dup_train <- train %>% count(.data[[id_col]]) %>% filter(n > 1) %>% nrow()
  dup_test  <- test  %>% count(.data[[id_col]]) %>% filter(n > 1) %>% nrow()
  cat("\nDuplicados por ID en train:", dup_train, " | en test:", dup_test, "\n")
} else {
  cat("\n(No hay duplicados)\n")
  cat("Filas duplicadas en train:", sum(duplicated(train)), "\n")
  cat("Filas duplicadas en test :", sum(duplicated(test)),  "\n")
}

getwd()
```
#Revis√≥n exaustiva de Na
```{r}


# Calcular % de faltantes en TRAIN hogares
faltantes_train <- train %>%
  summarise(across(everything(), ~mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Porcentaje_NA") %>%
  mutate(Base = "Entrenamiento")

# Calcular % de faltantes en TEST hogares
faltantes_test <- test %>%
  summarise(across(everything(), ~mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Porcentaje_NA") %>%
  mutate(Base = "Prueba")

# Unir ambas bases
faltantes_comp <- bind_rows(faltantes_train, faltantes_test)


# Gr√°fico comparativo con leyenda inferior
grafico_faltantes <- ggplot(faltantes_comp, aes(x = Variable, y = Porcentaje_NA, fill = Base)) +
  geom_bar(stat = "identity", position = "dodge", color = "gray30") +
  geom_text(
    aes(label = paste0(round(Porcentaje_NA, 2), "%")),
    position = position_dodge(width = 0.9),
    vjust = -0.3, size = 3
  ) +
  coord_flip() +
  labs(
    title = "Comparaci√≥n de % de valores faltantes por variable\nTrain vs Test",
    x = "Variable",
    y = "% de valores faltantes",
    fill = "Base de datos"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    legend.position = "bottom",              # üîπ Mueve la leyenda abajo
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 10),
    axis.text.y = element_text(size = 9),
    axis.text.x = element_text(size = 9),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank()
  ) +
  scale_fill_manual(
    values = c("Entrenamiento" = "lightyellow4", "Prueba" = "#FFFF00")
  )



#Gardar Gr√°fica

root_dir <- here::here()

# Crea subrutas relativas al proyecto
path_outputs <- file.path(root_dir, "outputs")
path_figures <- file.path(path_outputs, "figures")

#PDF
ggsave(
  filename = file.path(path_figures, "Faltantes_Trains.pdf"),
  plot = grafico_faltantes,
  width = 10, height = 6
)

#PNG
ggsave(
  filename = file.path(path_figures, "Faltantes_Trains.png"),
  plot = grafico_faltantes,
  width = 10, height = 6,
  dpi = 300
)

# Mostrar en pantalla
print(grafico_faltantes)



```
## Revisi√≥n outliers

```{r}

# Seleccionar variables num√©rica
vars_outliers <- train %>%
  select(where(is.numeric)) %>%
  select(-any_of(c("price", "year", "lon", "lat", "month")))

#‚É£ Pasar a formato largo
vars_long <- vars_outliers %>%
  pivot_longer(cols = everything(),
               names_to = "Variable",
               values_to = "Valor")

#  Graficar boxplots 
grafico_outliers <- ggplot(vars_long, aes(x = Variable, y = Valor)) +
  geom_boxplot(fill = "#87CEFA", color = "gray30", outlier.colour = "red", alpha = 0.6, width = 0.6) +
  coord_flip() +
  labs(
    title = "Detecci√≥n de outliers",
    x = "Variable",
    y = "Valor"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 15),
    axis.title.x = element_text(size = 12, margin = margin(t = 10)),
    axis.title.y = element_text(size = 12, margin = margin(r = 10)),
    axis.text.y = element_text(size = 11),
    axis.text.x = element_text(size = 10),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank()
  )


print(grafico_outliers)

#Gurdamos gr√°fica

# Ruta din√°mica
root_dir <- here::here()
path_outputs <- file.path(root_dir, "outputs")
path_figures <- file.path(path_outputs, "figures")
dir.create(path_figures, recursive = TRUE, showWarnings = FALSE)


#PDF
ggsave(
  filename = file.path(path_figures, "Outliers.pdf"),
  plot = grafico_outliers,
  width = 9, height = 12, dpi = 300
)
#PNG
ggsave(
  filename = file.path(path_figures, "Outliers.png"),
  plot = grafico_outliers,
  width = 9, height = 12, dpi = 300
)

#Revismos si hay observaciones donde el cubierto sea mayor que el total
train %>%
  filter(surface_covered > surface_total) %>%
  select(surface_total, surface_covered)
```

## Variables nuevas a partir de texto

```{r}

# Normalizador de texto - funci√≥n 
texto_normal <- function(x) {
  x %>%
    tidyr::replace_na("") %>%
    stringi::stri_trans_general("Latin-ASCII") %>% # quita tildes
    tolower() %>%
    stringr::str_squish()
}

# Diccionario de atributos (regex) para dummies desde title+description 
# Puedes ajustar/expandir vocabulario seg√∫n tu mercado
attr_patterns <- list(
  ubic_parque          = "\\bparques?\\b(?!adero)",                             # parque, no parqueadero
  parqueadero_garaje   = "\\b(parqueadero|garaje|estacionamiento)s?\\b",
  transporte_metro_tm  = "\\b(metro|transmilenio|sitp|subte|estacion|paradero)\\b",
  colegio_universidad  = "\\b(colegios?|universidades?|jardin(?:es)? infantil(?:es)?)\\b",
  salud_hospital       = "\\b(hospital(es)?|clinica(s)?|centro(s)? medico(s)?)\\b",
  centro_comercial     = "\\b(centro(s)? comercial(es)?)\\b",
  supermercado         = "\\b(supermercado(s)?|tienda(s)?|exito|carulla|jumbo|olimpica|d1|ara)\\b",
  seguridad            = "\\b(vigilancia|porteri[ai]|seguridad|camaras?)\\b",
  amenities            = "\\b(piscina|gimnasio|bbq|sal[o√≥]n social|zona social|zona infantil)\\b",
  ascensor             = "\\bascensor(es)?\\b",
  balcon               = "\\bbalcon(es)?\\b",
  terraza              = "\\bterraza(s)?\\b",
  remodelado           = "\\b(remodelad[oa]s?|remodelaci[o√≥]n)\\b",
  cocina_integral      = "\\bcocina integral\\b",
  iluminacion          = "\\biluminaci[o√≥]n\\b",
  ventilacion          = "\\bventilaci[o√≥]n\\b",
  patio                = "\\bpatio(s)?\\b",
  estudio              = "\\bestudio(s)?\\b",
  deposito             = "\\bdepo[si]t[o√≥]s?\\b|\\bbaulera(s)?\\b|\\btrastero(s)?\\b",
  chimenea             = "\\bchimenea(s)?\\b",
  walk_in_closet       = "\\b(vestier|walk(?:-|\\s*)in\\s*closet)\\b",
  vista                = "\\b(vista|panor[a√°]mica)\\b",
  exterior_interior    = "\\b(exterior|interior|esquinero|esquina)\\b",
  estrato              = "\\bestrato\\s*[1-6]\\b"
)

# --- 3) Funci√≥n: construir dummies desde texto ---
add_text_flags <- function(df, patterns = attr_patterns) {
  stopifnot(all(c("title","description") %in% names(df)))
  txt <- texto_normal(paste(df$title, df$description))
  out <- df
  for (nm in names(patterns)) {
    rx <- stringr::regex(patterns[[nm]], ignore_case = TRUE)
    out[[paste0("has_", nm)]] <- as.integer(stringr::str_detect(txt, rx))
  }
  out
}

# --- 4) Aplica procesamiento a train/test ---
train_txt <- add_text_flags(train)
test_txt  <- add_text_flags(test)

# --- 5) Evaluaci√≥n univariada vs price en TRAIN (cobertura, efecto, %Œî, eta¬≤) ---
target <- "price"

score_one_attr <- function(df, attr_col, target = "price") {
  # grupos por flag
  g <- df |>
    dplyr::summarise(
      mean1 = mean(.data[[target]][.data[[attr_col]] == 1], na.rm = TRUE),
      mean0 = mean(.data[[target]][.data[[attr_col]] == 0], na.rm = TRUE),
      n1    = sum(.data[[attr_col]] == 1, na.rm = TRUE),
      n0    = sum(.data[[attr_col]] == 0, na.rm = TRUE),
      .groups = "drop"
    )
  effect   <- g$mean1 - g$mean0
  pct_diff <- ifelse(is.finite(g$mean0) && g$mean0 != 0, effect / g$mean0, NA_real_)
  # eta¬≤ (varianza explicada por 2 grupos)
  grand    <- mean(df[[target]], na.rm = TRUE)
  ss_between <- g$n1 * (g$mean1 - grand)^2 + g$n0 * (g$mean0 - grand)^2
  ss_total   <- sum((df[[target]] - grand)^2, na.rm = TRUE)
  eta2 <- ifelse(ss_total > 0, ss_between / ss_total, 0)
  tibble(
    attribute = attr_col,
    support_1 = g$n1,
    rate_1    = (g$n1)/(g$n1 + g$n0),
    mean_price_1 = g$mean1,
    mean_price_0 = g$mean0,
    mean_diff    = effect,
    pct_diff     = pct_diff,
    eta2         = eta2
  )
}

flag_cols <- names(train_txt) |> (\(v) v[stringr::str_starts(v, "has_")])()
stats_tbl <- purrr::map_dfr(flag_cols, ~score_one_attr(train_txt, .x, target = target))

# Ranking: cobertura m√≠nima, tama√±o de efecto y eta¬≤ (ajusta pesos si quieres)
min_rate <- 0.03  # >= 3% de menciones
ranked <- stats_tbl |>
  mutate(rank_score = eta2 * 0.5 + abs(pct_diff) * 0.3 + rate_1 * 0.2) |>
  filter(rate_1 >= min_rate) |>
  arrange(desc(rank_score))

# --- 6) Reducir redundancia entre dummies (phi) y elegir TOP-4 ---
phi_bin <- function(a, b) {
  pa <- mean(a); pb <- mean(b)
  cov <- mean(a*b) - pa*pb
  denom <- sqrt(pa*(1-pa)*pb*(1-pb))
  if (!is.finite(denom) || denom == 0) return(0)
  cov/denom
}

# matriz phi en candidatas
cand <- ranked$attribute
Phi <- matrix(NA_real_, nrow = length(cand), ncol = length(cand), dimnames = list(cand, cand))
for (i in seq_along(cand)) {
  for (j in seq_along(cand)) {
    if (i == j) { Phi[i, j] <- 1; next }
    a <- as.integer(train_txt[[cand[i]]]); b <- as.integer(train_txt[[cand[j]]])
    Phi[i, j] <- phi_bin(a, b)
  }
}

picked <- character(0)
for (nm in ranked$attribute) {
  if (length(picked) == 4) break
  ok <- all(abs(Phi[nm, picked, drop = FALSE]) <= 0.8)
  if (ok) picked <- c(picked, nm)
}

top4 <- picked
top4
#> vector con los 4 "has_*" seleccionados autom√°ticamente

# --- 7) Crear SOLO esas 4 dummies finales coherentes en train/test ---
add_top4 <- function(df, final_names) {
  # Asegura columnas aunque alguna no aparezca en test
  for (nm in final_names) if (!nm %in% names(df)) df[[nm]] <- 0L
  df |>
    mutate(across(all_of(final_names), ~as.integer(.))) 
}

train_ready <- add_top4(train_txt, top4)
test_ready  <- add_top4(test_txt,  top4)

# --- 8) Peque√±as tablas para el informe (justificaci√≥n reproducible) ---
justificacion <- ranked |>
  filter(attribute %in% top4) |>
  select(attribute, support_1, rate_1, mean_price_1, mean_price_0, mean_diff, pct_diff, eta2, rank_score)

justificacion |>
  arrange(desc(rank_score)) |>
  mutate(pct_diff = scales::percent(pct_diff, accuracy = 0.1),
         rate_1   = scales::percent(rate_1, accuracy = 0.1)) |>
  select(attribute, rate_1, mean_price_1, mean_price_0, pct_diff, eta2)

```


```{r}


# ===============================
# 7) Distribuciones (gr√°ficos sencillos)
# ===============================

# 7.1 Histograma para cada num√©rica (train)
if (length(num_cols) > 0) {
  train %>%
    select(all_of(num_cols)) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "valor") %>%
    ggplot(aes(x = valor)) +
    geom_histogram(bins = 30) +
    facet_wrap(~ variable, scales = "free", ncol = 3) +
    labs(title = "Histogramas (TRAIN)", x = NULL, y = "Frecuencia")
}

# 7.2 Densidad del target (train), si existe
if (target %in% names(train)) {
  # Densidad en escala original
  ggplot(train, aes(x = .data[[target]])) +
    geom_density() +
    labs(title = paste("Densidad de", target, "(TRAIN)"), x = target, y = "Densidad")

  # Densidad en log (opcional)
  if (all(is.finite(train[[target]]), na.rm = TRUE)) {
    ggplot(train %>% filter(.data[[target]] > 0), aes(x = log1p(.data[[target]]))) +
      geom_density() +
      labs(title = paste("Densidad de log1p(", target, ") (TRAIN)"), x = paste0("log1p(", target, ")"), y = "Densidad")
  }
}

# 7.3 Boxplots del target por algunas categ√≥ricas (top k categor√≠as m√°s frecuentes)
top_k_levels <- function(x, k = 12) {
  forcats::fct_lump_n(x, n = k, other_level = "otros")
}

if (target %in% names(train) && length(cat_cols) > 0) {
  for (cc in cat_cols) {
    p <- train %>%
      mutate(..grp = top_k_levels(.data[[cc]], k = 12)) %>%
      ggplot(aes(x = ..grp, y = .data[[target]])) +
      geom_boxplot(outlier.alpha = 0.2) +
      coord_flip() +
      labs(title = paste("Boxplot de", target, "por", cc, "(TRAIN)"),
           x = cc, y = target)
    print(p)
  }
}

# 7.4 Pares de variables (scatter) para algunas num√©ricas clave
pairs_cols <- intersect(num_cols, c("bathrooms","bedrooms","rooms","surface_total","surface_covered","lat","lon","year","month"))
if (length(pairs_cols) >= 2 && target %in% names(train)) {
  df_pairs <- train %>% select(all_of(pairs_cols), all_of(target)) %>% drop_na()
  GGally::ggpairs(df_pairs, columns = 1:length(pairs_cols),
                  title = "Matriz de pares (subset num√©rico) - TRAIN")
}

# ===============================
# 8) Correlaciones num√©ricas
# ===============================
if (length(num_cols) >= 2) {
  # correlaciones entre num√©ricas (train)
  cormat <- train %>% select(all_of(num_cols)) %>%
    mutate(across(everything(), as.numeric)) %>%
    cor(use = "pairwise.complete.obs")

  ggcorrplot::ggcorrplot(cormat, lab = FALSE, type = "lower") +
    ggtitle("Correlaci√≥n entre variables num√©ricas (TRAIN)")

  # correlaci√≥n con target si num√©rico
  if (target %in% names(train) && is.numeric(train[[target]])) {
    cor_with_target <- train %>%
      select(all_of(num_cols), all_of(target)) %>%
      cor(use = "pairwise.complete.obs") %>%
      as.data.frame() %>%
      rownames_to_column("variable") %>%
      select(variable, all_of(target)) %>%
      arrange(desc(abs(.data[[target]])))
    cat("\nCorrelaci√≥n con el target (TRAIN):\n")
    print(cor_with_target)
  }
}

# ===============================
# 9) Recomendaci√≥n de columnas a modelar
# ===============================
keep_features <- setdiff(cols_common, target)  # lo com√∫n menos la y
cat("\nFeatures a usar (comunes, sin target):\n")
print(keep_features)
```



# Variables Internas (4 variables que salen de la columna de texto en ambas bases de datos)
```{r}

# Normaliza: min√∫sculas, sin tildes, espacios compactados
texto_normal <- function(x) {
  x %>%
    tidyr::replace_na("") %>%
    stringi::stri_trans_general("Latin-ASCII") %>%
    tolower() %>%
    stringr::str_squish()
}

# Crea las 4 dummies desde title + description
add_text_dummies <- function(df) {
  stopifnot(all(c("title","description") %in% names(df)))
  
  txt <- texto_normal(paste(df$title, df$description))
  
  # Patrones (regex) ‚Äî puedes ajustar si quieres ampliar vocabulario
  rx_parqueadero_garaje <- stringr::regex("\\b(parqueadero|garaje|estacionamiento)s?\\b", ignore_case = TRUE)
  rx_cocina_integral    <- stringr::regex("\\bcocina integral\\b", ignore_case = TRUE)
  rx_estudio            <- stringr::regex("\\bestudio(s)?\\b", ignore_case = TRUE)
  rx_chimenea           <- stringr::regex("\\bchimenea(s)?\\b", ignore_case = TRUE)
  
  df %>%
    mutate(
      has_parqueadero_garaje = as.integer(stringr::str_detect(txt, rx_parqueadero_garaje)),
      has_cocina_integral    = as.integer(stringr::str_detect(txt, rx_cocina_integral)),
      has_estudio            = as.integer(stringr::str_detect(txt, rx_estudio)),
      has_chimenea           = as.integer(stringr::str_detect(txt, rx_chimenea))
    )
}

# === Uso ===
# train ya cargado como data.frame/tibble con columnas title y description
train_ready <- add_text_dummies(train)
test_ready <- add_text_dummies(test)

# (Opcional) ver cobertura de cada dummie en train
colMeans(dplyr::select(train_ready, starts_with("has_")))
colMeans(dplyr::select(test_ready, starts_with("has_")))

```

## Obtenci√≥n de variables a partir de otras fuentes

### Variables de Open Street Map

1. Carga datos de viviendas (train y test)
2. Usa informaci√≥n de OpenStreetMap para:
   - Asociar barrio y localidad
   - Calcular distancia a parques, colegios, restaurantes, autopistas y centros comerciales
3. Si los datos procesados ya existen en formato .rds, los carga directamente
(para evitar volver a correr la carga pesada del archivo OSM .pbf)


```{r}


#  Configuraci√≥n inicial


# Aumentar tiempo m√°ximo de descarga/lectura y tolerar geometr√≠as
options(timeout = 1800)
#permite geometrias no cerradas para identificar barrios y localidades
Sys.setenv(OGR_GEOMETRY_ACCEPT_UNCLOSED_RING = "YES")

# Desactivar motor s2 para evitar errores de topolog√≠a
sf_use_s2(FALSE)

if (!dir.exists("outputs")) dir.create("outputs")

# Definir rutas de salida para archivos procesados
train_rds <- "outputs/train_ready_osm_bogota_local.rds"
test_rds  <- "outputs/test_ready_osm_bogota_local.rds"

#Para no volver a procesar, si existen los rds, se cargan con el siguiente comando

if (file.exists(train_rds) & file.exists(test_rds)) {
  message("Archivos .RDS encontrados. Cargando datos procesados...")
  
  train_ready_osm <- readRDS(train_rds)
  test_ready_osm  <- readRDS(test_rds)
  
} else {
 message("No se encontraron .RDS. Iniciando procesamiento desde OpenStreetMap...")

# Ruta local al archivo PBF de Colombia descargado de GeoFabrik

  # Ruta local del archivo .pbf descargado de GeoFabrik
  file_pbf <- "data/external/colombia-251105.osm.pbf"



#  Lectura de datos OSM (desde archivo local)

polys  <- oe_read(file_pbf, layer = "multipolygons", quiet = TRUE)
points <- oe_read(file_pbf, layer = "points", quiet = TRUE)
lines  <- oe_read(file_pbf, layer = "lines", quiet = TRUE)

# Reparar geometr√≠as inv√°lidas
polys  <- st_make_valid(polys) |> st_buffer(0)
points <- st_make_valid(points)
lines  <- st_make_valid(lines)

# Filtrar a Bogot√° (bounding box aproximado)

bbox_bogota <- st_as_sfc(st_bbox(c(
  xmin = -74.35, xmax = -73.9,
  ymin = 4.45, ymax = 4.85
), crs = 4326))

polys_bogota  <- suppressWarnings(st_crop(polys, bbox_bogota))
points_bogota <- suppressWarnings(st_crop(points, bbox_bogota))
lines_bogota  <- suppressWarnings(st_crop(lines, bbox_bogota))


#  Extraer Localidades y Barrios


localidades <- polys_bogota %>%
  filter(admin_level == "8") %>%
  select(name) %>%
  rename(localidad = name)

barrios <- polys_bogota %>%
  filter(admin_level == "10" | place == "neighbourhood") %>%
  select(name) %>%
  rename(barrio = name)

# Puntos de inter√©s (POI)

get_poi_safe <- function(data, col, values) {
  if (!col %in% names(data)) {
    message("o existe la columna '", col, "' en esta capa.")
    return(NULL)
  }
  data %>% filter(.data[[col]] %in% values)
}

# Funci√≥n robusta que busca en todas las capas disponibles
get_poi_all <- function(points, polys, lines, key, values) {
  capas <- list(points, polys, lines)
  pois <- purrr::map_dfr(capas, function(x) {
    if (!key %in% names(x)) return(NULL)
    x %>% filter(.data[[key]] %in% values)
  })
  if (nrow(pois) == 0) return(NULL)
  pois
}

# Crear lista de puntos de inter√©s combinando todas las capas
pois_list <- list(
  # Parques y zonas de recreo (incluye golf)
  parques = get_poi_all(
    points_bogota, polys_bogota, lines_bogota,
    key = "leisure",
    values = c("park", "garden", "recreation_ground", "playground", "golf_course")
  ),
  
  # Colegios, jardines infantiles, universidades
  colegios = get_poi_all(
    points_bogota, polys_bogota, lines_bogota,
    key = "amenity",
    values = c("school", "kindergarten", "college", "university")
  ),
  
  # Restaurantes, cafeter√≠as y comida r√°pida
  restaurantes = get_poi_all(
    points_bogota, polys_bogota, lines_bogota,
    key = "amenity",
    values = c("restaurant", "fast_food", "cafe")
  ),
  
  # Autopistas y v√≠as principales
  autopistas = get_poi_all(
    points_bogota, polys_bogota, lines_bogota,
    key = "highway",
    values = c("motorway", "trunk", "primary")
  ),
  
  # Centros comerciales y supermercados grandes
  centros_comerciales = get_poi_all(
    points_bogota, polys_bogota, lines_bogota,
    key = "shop",
    values = c("mall", "supermarket")
  )
)


# Eliminar vac√≠os (NULL o sin filas)
pois_list <- purrr::discard(pois_list, ~is.null(.) || nrow(.) == 0)


purrr::walk(names(pois_list), function(nm) {
  cat(sprintf("  - %-20s %5d registros\n", nm, nrow(pois_list[[nm]])))
})


# Convertirs bases a  objetos espaciales

train_sf <- st_as_sf(train_ready, coords = c("lon", "lat"), crs = 4326, remove = FALSE)
test_sf  <- st_as_sf(test_ready,  coords = c("lon", "lat"), crs = 4326, remove = FALSE)

# Transformar todo a proyecci√≥n m√©trica (EPSG:3116)
train_sf <- st_transform(train_sf, 3116)
test_sf  <- st_transform(test_sf, 3116)
localidades <- st_transform(localidades, 3116)
barrios <- st_transform(barrios, 3116)
pois_sf <- map(pois_list, ~st_transform(., 3116))


#  Calcular distancias a cada tipo de POI


calc_min_dist <- function(x, y) {
  if (is.null(y) || nrow(y) == 0) return(rep(NA, nrow(x)))
  st_distance(x, y) %>%
    apply(1, min) %>%
    set_units("m") %>%
    drop_units()
}

for (nm in names(pois_sf)) {
  train_sf[[paste0("dist_", nm)]] <- calc_min_dist(train_sf, pois_sf[[nm]])
  test_sf[[paste0("dist_", nm)]]  <- calc_min_dist(test_sf, pois_sf[[nm]])
}

#  Uni√≥n espacial con barrios y localidades


train_sf <- train_sf %>%
  st_join(barrios, join = st_within) %>%
  st_join(localidades, join = st_within)

test_sf <- test_sf %>%
  st_join(barrios, join = st_within) %>%
  st_join(localidades, join = st_within)

#Aseguramos el CRS correcto
st_crs(train_espacial) <- NA
st_crs(test_espacial)  <- NA

st_crs(train_espacial) <- 4326
st_crs(test_espacial)  <- 4326

#Eliminar geometria y guardar
train_ready_osm <- st_drop_geometry(train_sf)
test_ready_osm  <- st_drop_geometry(test_sf)

# Exportar dataset


  saveRDS(train_ready_osm, train_rds)
  saveRDS(test_ready_osm,  test_rds)
}
colnames(train_ready_osm)
```


## Viviendas en venta del test y train

En esta secci√≥n se gr√°fica las viviendas obtenidas en la base de datos de entrenamiento y de testeo visualizando concentraciones de vivienda.

```{r}

#  Asegurar sf + CRS
to_sf_4326 <- function(df) {
  if ("sf" %in% class(df)) return(st_transform(df, 4326))
  st_as_sf(df, coords = c("lon","lat"), crs = 4326, remove = FALSE)
}

train_sf <- to_sf_4326(train_ready_osm)
test_sf  <- to_sf_4326(test_ready_osm)

train_sf$dataset <- "Train"
test_sf$dataset  <- "Test"
viviendas_sf     <- bind_rows(train_sf, test_sf)

# Foondos de localidades y barrios
bg_layers <- list()

if (exists("localidades") && inherits(localidades, "sf") && nrow(localidades) > 0) {
  bg_layers$localidades <- st_transform(localidades, 4326)
}
if (exists("barrios") && inherits(barrios, "sf") && nrow(barrios) > 0) {
  bg_layers$barrios <- st_transform(barrios, 4326)
}

# Extensi√≥n del mapa: 
bb   <- st_bbox(viviendas_sf)
padx <- diff(range(c(bb["xmin"], bb["xmax"]))) * 0.05  # 5% de margen
pady <- diff(range(c(bb["ymin"], bb["ymax"]))) * 0.05

xlim <- c(bb["xmin"] - padx, bb["xmax"] + padx)
ylim <- c(bb["ymin"] - pady, bb["ymax"] + pady)

# Mapa en ggplot2
m  <- ggplot()

# Fondo: localidades
if (!is.null(bg_layers$localidades)) {
m <- m + geom_sf(data = bg_layers$localidades, fill = NA, color = "grey70", linewidth = 0.3)
}

# Fondo: barrios 
if (!is.null(bg_layers$barrios)) {
  m <- m + geom_sf(data = bg_layers$barrios, fill = NA, color = "grey85", linewidth = 0.2)
}

# Puntos de viviendas
m <- m +
  geom_sf(data = viviendas_sf,
          aes(color = dataset),
          size = 0.35, alpha = 0.7, show.legend = TRUE) +
  scale_color_manual(values = c("Train" = "#1E88E5", "Test" = "#E53935"),
                     name = "Conjunto de datos") +
  coord_sf(xlim = xlim, ylim = ylim, expand = FALSE) +
  theme_minimal(base_size = 11) +
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 10),
    legend.text  = element_text(size = 9),
    panel.grid = element_blank(),
    axis.text.x = element_text(size = 8),   # ejes m√°s peque√±os
    axis.text.y = element_text(size = 8),
    plot.title  = element_text(face = "bold", hjust = 0.5)
  ) +
  labs(
    title = "Viviendas en Bogot√°",
    x = "Longitud", y = "Latitud"
  )

m

#  Guardar
dir.create("outputs/figures", recursive = TRUE, showWarnings = FALSE)
ggsave("outputs/figures/mapa_train_test_bogota.png", m , width = 8, height = 6, dpi = 300)

```

## Mapa de viviendas y puntos de inter√©s


```{r}
# Asegurar que todos los objetos est√©n en CRS 3116
train_sf <- st_transform(train_sf, 3116)
pois_sf  <- map(pois_sf, ~st_transform(., 3116))
barrios  <- st_transform(barrios, 3116)
localidades <- st_transform(localidades, 3116)

# Convertir pol√≠gonos a centroides (si existen)
pois_sf <- map(pois_sf, function(x) {
  if (any(grepl("POLYGON", unique(st_geometry_type(x))))) {
    x <- st_centroid(x)
  }
  x
})

# Combinar todos los POIs en una sola capa con una columna "tipo"
pois_union <- map2_dfr(pois_sf, names(pois_sf), ~mutate(.x, tipo = .y))

# Asegurar que "tipo" sea un factor ordenado con nombres legibles
pois_union <- pois_union %>%
  mutate(tipo = factor(
    tipo,
    levels = c("parques", "colegios", "restaurantes", "autopistas", "centros_comerciales"),
    labels = c("Parques", "Colegios", "Restaurantes", "Autopistas", "Centros comerciales")
  ))

# Colores para los distintos puntos de inter√©s
colores_poi <- c(
  "Parques" = "#4CAF50",
  "Colegios" = "#FFD600",
  "Restaurantes" = "#E64A19",
  "Autopistas" = "#1565C0",
  "Centros comerciales" = "#9C27B0"
)

# Crear bounding box extendido a partir de las viviendas
bb <- st_bbox(train_sf)
padx <- (bb["xmax"] - bb["xmin"]) * 0.05
pady <- (bb["ymax"] - bb["ymin"]) * 0.05
xlim <- c(bb["xmin"] - padx, bb["xmax"] + padx)
ylim <- c(bb["ymin"] - pady, bb["ymax"] + pady)

# Graficar mapa
m_poi<-ggplot() +
  # Localidades de fondo
  geom_sf(data = localidades, fill = "gray95", color = "gray85", size = 0.2) +
  
  # Barrios
  geom_sf(data = barrios, fill = NA, color = "gray90", size = 0.1) +
  
  # Viviendas (Train)
  geom_sf(data = train_sf, color = "black", size = 0.25, alpha = 0.5) +

  # Puntos de inter√©s
  geom_sf(data = pois_union, aes(color = tipo), size = 0.7, alpha = 0.7, show.legend = TRUE) +

  # Escala de colores y leyenda corregida
  scale_color_manual(
    values = colores_poi,
    name = "Punto de inter√©s"
  ) +

  # L√≠mites espaciales
  coord_sf(xlim = xlim, ylim = ylim, expand = FALSE) +

  # T√≠tulos y etiquetas
  labs(
    title = "Viviendas y Puntos de Inter√©s",
    subtitle = "Fuentes: OpenStreetMap y GeoFabrik Colombia",
    x = "Coordenada Este (metros)", 
    y = "Coordenada Norte (metros)"
  ) +

  # Estilo gr√°fico
  theme_minimal(base_size = 11) +
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 9),
    panel.grid = element_blank(),
    axis.text.x = element_text(size = 8),
    axis.text.y = element_text(size = 8),
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

#  Guardar
dir.create("outputs/figures", recursive = TRUE, showWarnings = FALSE)
ggsave("outputs/figures/mapa_train_pois_bogota.png", m_poi , width = 8, height = 6, dpi = 300)


m_poi
```
## Transformaciones a las variables espaciales

El objetivo de estas transformaciones es capturar c√≥mo la proximidad a ciertos puntos de inter√©s influye en el valor de una vivienda, diferenciando entre efectos positivos y negativos seg√∫n la distancia.

- Autopistas: vivir justo al lado reduce el valor (ruido, contaminaci√≥n), pero estar cerca ‚Äîsin estar expuesto‚Äî puede ser positivo por accesibilidad.

- Parques y zonas verdes: mayor valor cuanto m√°s cerca, aunque con rendimientos decrecientes, por eso se usa una transformaci√≥n logar√≠tmica.

- Colegios y jardines: un punto √≥ptimo entre 100 m y 500 m, balanceando conveniencia y externalidades (ruido, tr√°fico).

- Centros comerciales: cercan√≠a moderada es deseable, pero el exceso de tr√°fico y ruido reduce el atractivo si se est√° demasiado cerca.

- Restaurantes y cafeter√≠as: capturan vitalidad urbana; la cercan√≠a tiende a ser positiva.

- Estaciones de transporte p√∫blico: cercan√≠a razonable mejora accesibilidad, pero el exceso de proximidad puede implicar congesti√≥n.
```{r}

# Transformaciones y categorizaciones de variables espaciales

procesar_distancias <- function(df) {
  df %>%
    mutate(
      # Parques y zonas verdes (incluye golf)
      dist_parques_log = log1p(dist_parques),

      #  Colegios y jardines 
      dist_colegios2 = dist_colegios^2,
      dist_colegios_cat = case_when(
        dist_colegios < 50 ~ "muy_cerca",
        dist_colegios <= 500 ~ "cerca_optima",
        TRUE ~ "lejos"
      ),

      # Restaurantes, cafeter√≠as y comida r√°pida
      dist_restaurantes_log = log1p(dist_restaurantes),

      #  Centros comerciale
      dist_malls_cat = case_when(
        dist_centros_comerciales <= 1000 ~ "cerca",
        dist_centros_comerciales <= 3000 ~ "media",
        TRUE ~ "lejos"
      ),

      # Autopistas
      dist_autopistas2 = dist_autopistas^2,
      dist_autopistas_cat = case_when(
        dist_autopistas < 50 ~ "muy_cerca",
        dist_autopistas >= 50 & dist_autopistas <= 500 ~ "cerca_optima",
        dist_autopistas > 500 ~ "lejos",
        TRUE ~ NA_character_
      )
    ) %>%
    mutate(
      # Convertir categ√≥ricas en factor con orden l√≥gico
      across(ends_with("_cat"), ~factor(., 
        levels = c("muy_cerca", "cerca_optima", "media", "lejos")
      ))
    )
} 

# Aplicar a train y test
train_osm <- procesar_distancias(train_ready_osm)
test_osm <- procesar_distancias(test_ready_osm)

# Guardar versiones actualizadas
saveRDS(train_osm, "outputs/train_sf_distancias_transformadas.rds")
saveRDS(test_osm,  "outputs/test_sf_distancias_transformadas.rds")


```

##Inclusi√≥n de estrato socioeconomico

```{r}
# Este bloque ejecuta un proceso de enriquecimiento de datos en tres pasos:
# 1. Carga las tres fuentes de datos: Lotes (geometr√≠a) y Estrato (datos).
# 2. Las une usando un c√≥digo de identificaci√≥n com√∫n (la "llave").
# 3. Une espacialmente el resultado final con las viviendas.
# 4. Realiza la uni√≥n espacial para asignar el estrato a cada vivienda.
# 5. Actualiza las bases finales y verifica el resultado.


# Definir rutas de salida para archivos procesados
train_rds_estrato <- "outputs/train_ready_osm_estrato.rds"
test_rds_estrato  <- "outputs/test_ready_osm_estrato.rds"

#Para no volver a procesar, si existen los rds, se cargan con el siguiente comando

if (file.exists(train_rds_estrato) & file.exists(test_rds_estrato)) {
  message("Archivos .RDS encontrados. Cargando datos procesados...")
  
  train_ready_osm_estrato <- readRDS(train_rds_estrato)
  test_ready_osm_estrato  <- readRDS(test_rds_estrato)
  
} else {
 message("No se encontraron .RDS. ")

  

# --- 1. Cargar Archivos Fuente ---
# Para mayor robustez, se recomienda tener estos archivos en la carpeta del proyecto.
ruta_gpkg <- "C:/Users/User/OneDrive/Documents/GitHub/Taller3_Making Money with ML/data/external/LOTE.gpkg"
ruta_estrato_csv <- "C:/Users/User/OneDrive/Documents/GitHub/Taller3_Making Money with ML/data/external/estrato.csv"

if (!file.exists(ruta_gpkg)) stop("¬°Archivo LOTE.gpkg no encontrado!")
lotes_sf <- sf::st_read(ruta_gpkg)
message("GeoPackage 'LOTE.gpkg' cargado.")

if (!file.exists(ruta_estrato_csv)) stop("¬°Archivo 'estrato.csv' no encontrado!")
estrato_csv_df <- readr::read_csv(ruta_estrato_csv)
message("Tabla de estrato 'estrato.csv' cargada.")


# --- 2. Preparar y Unir Lotes con Estratos ---

lotes_preparado_sf <- lotes_sf %>%
  dplyr::rename(codigo_lote_llave = LOTCODIGO) %>%
  dplyr::mutate(codigo_lote_llave = as.character(codigo_lote_llave))

estrato_preparado_df <- estrato_csv_df %>%
  dplyr::rename(codigo_lote_llave = ESOCLOTE) %>%
  dplyr::mutate(codigo_lote_llave = as.character(codigo_lote_llave)) %>%
  # Paso CRUCIAL: Eliminamos lotes duplicados para asegurar una uni√≥n 1 a 1.
  dplyr::distinct(codigo_lote_llave, .keep_all = TRUE)

# Realizamos la uni√≥n (merge)
message("Uniendo Lotes y Estratos por el c√≥digo del lote...")
lotes_con_estrato_sf <- lotes_preparado_sf %>%
  dplyr::left_join(estrato_preparado_df, by = "codigo_lote_llave") %>%
  # Seleccionamos solo las columnas que necesitamos para el paso final.
  dplyr::select(estrato = ESOESTRATO, geom) %>%
  # Filtramos lotes que no lograron obtener un estrato
  dplyr::filter(!is.na(estrato)) %>%
  dplyr::mutate(estrato = as.factor(estrato))
message("¬°Uni√≥n completada!")


# --- 3. Preparar Bases de Viviendas para Uni√≥n Espacial ---

# Aseguramos que las bases de viviendas (train/test) sean objetos 'sf'
# y tengan el sistema de coordenadas correcto.
message("\nPreparando bases de datos de viviendas...")

# Convertir train_ready_osm a 'sf'
if (!inherits(train_ready_osm, "sf")) {
  train_sf <- sf::st_as_sf(train_ready_osm, coords = c("lon", "lat"), crs = 4326, remove = FALSE)
} else {
  train_sf <- train_ready_osm
}

# Convertir test_ready_osm a 'sf'
if (!inherits(test_ready_osm, "sf")) {
  test_sf <- sf::st_as_sf(test_ready_osm, coords = c("lon", "lat"), crs = 4326, remove = FALSE)
} else {
  test_sf <- test_ready_osm
}

# Unificar TODOS los CRS a EPSG:3116 para la uni√≥n espacial.
message("Unificando Sistemas de Coordenadas (CRS) a EPSG:3116...")
lotes_con_estrato_sf <- sf::st_transform(lotes_con_estrato_sf, crs = 3116)
train_sf <- sf::st_transform(train_sf, crs = 3116)
test_sf  <- sf::st_transform(test_sf, crs = 3116)
message("¬°Todos los CRS unificados!")


# --- 4. Realizar la Uni√≥n Espacial ---
# Asignamos el estrato a cada vivienda seg√∫n su ubicaci√≥n.
message("\nRealizando uni√≥n espacial con la base de entrenamiento...")
train_final_sf <- sf::st_join(train_sf, lotes_con_estrato_sf, join = st_intersects, left = TRUE)

message("Realizando uni√≥n espacial con la base de prueba...")
test_final_sf  <- sf::st_join(test_sf, lotes_con_estrato_sf, join = st_intersects, left = TRUE)


# --- 5. Verificaci√≥n y Finalizaci√≥n ---
message("\n--- Resultados de la Uni√≥n ---")
cat("Estratos asignados en TRAIN:", sum(!is.na(train_final_sf$estrato)), "de", nrow(train_final_sf), "\n")
cat("Estratos asignados en TEST:",  sum(!is.na(test_final_sf$estrato)),  "de", nrow(test_final_sf),  "\n")

# Actualizamos nuestras bases de datos finales.
# Esta vez nos aseguramos de no duplicar columnas y de manejar la geometr√≠a correctamente.
train_ready_osm_estrato <- sf::st_drop_geometry(train_final_sf)
test_ready_osm_estrato  <- sf::st_drop_geometry(test_final_sf)

# Verificamos que la columna 'estrato' fue a√±adida
glimpse(train_ready_osm_estrato)

message("\n¬°PROCESO COMPLETADO! La columna 'estrato' ha sido a√±adida a 'train_ready_osm' y 'test_ready_osm'.")

# --- 6. (Opcional) Guardar resultados y visualizar ---
dir.create("outputs", showWarnings = FALSE)
readr::write_csv(train_ready_osm_estrato, "outputs/train_final_con_estrato.csv")
message("\nBase de entrenamiento final guardada en la carpeta 'outputs'.")

# Gr√°fico de validaci√≥n visual
ggplot() +
  geom_sf(data = lotes_con_estrato_sf, aes(fill = estrato), color = NA, alpha = 0.5) +
  geom_sf(data = head(train_sf, 1000), color = "black", size = 0.5) + # Graficamos solo 1000 puntos para que sea r√°pido
  scale_fill_viridis_d(name = "Estrato") +
  theme_minimal() +
  labs(title = "Validaci√≥n Visual de Estratos y Viviendas",
       subtitle = "Pol√≠gonos = Lotes con estrato, Puntos = Viviendas (muestra)")


# Exportar dataset


  saveRDS(train_ready_osm_estrato, train_rds_estrato)
  saveRDS(test_ready_osm_estrato,  test_rds_estrato)
}
##
```
