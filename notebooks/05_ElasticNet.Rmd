---
title: "elasticnet"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#LIBRERIAS
```{r}
# Instalar y cargar pacman (gestor de paquetes)
knitr::opts_chunk$set(echo = TRUE)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
  tidyverse, readr, janitor, skimr, naniar, DataExplorer,
  GGally, ggcorrplot, lubridate, dplyr, tidyr, stringr, stringi, purrr, tibble, here, webshot2, gt, osmdata, sf, tidyverse, here, units, progressr,osmextract, rosm, ggspatial, prettymapr, nngeo, RANN, textclean, spatialsample, blockCV, tidymodels
)
```

Cargar bases finales
```{r}
testEN <- read_csv("C:/Users/laura/OneDrive/Documentos/GitHub/Taller3_Making-Money-with-ML/data/processed/test_final.csv")
trainEN <- read_csv("C:/Users/laura/OneDrive/Documentos/GitHub/Taller3_Making-Money-with-ML/data/processed/train_final.csv")
```

preparar datasets de test y train para modelar
```{r}
library(dplyr)


# ================================
# 1. PREPARAR DATASETS BASE
# ================================

train_modelo_EN <- trainEN %>% 
  select(-property_id, -title, -description, -city, -operation_type,
         -has_pisos_vivienda, -has_cocina_integral, -has_salon_social, -barrio, -rooms)

test_modelo_EN <- testEN %>% 
  select(-property_id, -title, -description, -city, -operation_type,
         -has_pisos_vivienda, -has_cocina_integral, -has_salon_social, -barrio, -rooms, -price)

```


Convertir a factor variables que aparecen en Character y tratamiento de NA
```{r}
# ========================================
# CORRECCIÓN DE VARIABLES CATEGÓRICAS
# ========================================

# Columnas categóricas problemáticas
factores <- c("localidad", "property_type")

# 1. Convertir estas columnas a carácter para controlar niveles manualmente
train_modelo_EN[factores] <- lapply(train_modelo_EN[factores], as.character)
test_modelo_EN[factores]  <- lapply(test_modelo_EN[factores], as.character)

# 2. Reemplazar NA por "OTRO" en ambas bases
for (col in factores) {
  train_modelo_EN[[col]][is.na(train_modelo_EN[[col]])] <- "OTRO"
  test_modelo_EN[[col]][is.na(test_modelo_EN[[col]])]   <- "OTRO"
}

# 3. Unificar todos los niveles posibles entre train y test
for (col in factores) {
  niveles_totales <- union(unique(train_modelo_EN[[col]]),
                           unique(test_modelo_EN[[col]]))
  
  train_modelo_EN[[col]] <- factor(train_modelo_EN[[col]], levels = niveles_totales)
  test_modelo_EN[[col]]  <- factor(test_modelo_EN[[col]],  levels = niveles_totales)
}


```


# ELASTIC NET 1
```{r}
library(tidyverse)
library(tidymodels)
library(glmnet)

# --- Log del target ---
train22 <- trainEN %>% mutate(price_log = log(price))
test22 <- testEN

# --- Recipe final ---
rec_en <- recipe(price_log ~ ., data = train22) %>%
  update_role(property_id, new_role = "ID") %>%
  step_rm(property_id, title, description) %>%
  step_zv(all_predictors()) %>%
  step_nzv(all_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors())

# --- Modelo final con hiperparámetros encontrados ---
final_en <- linear_reg(
  mode = "regression",
  penalty = 1e-04,       # lambda óptimo
  mixture = 0.1111111    # alpha óptimo
) %>% 
  set_engine("glmnet")

wf_final <- workflow() %>%
  add_recipe(rec_en) %>%
  add_model(final_en)

# --- Entrenar modelo final ---
set.seed(123)
fit_en <- wf_final %>% fit(data = train22)

# --- Predecir en test ---
pred_log <- predict(fit_en, test22)

# Volver del log al precio ---
pred_price <- exp(pred_log$.pred)

# Redondear a entero ---
pred_price <- round(pred_price)

```







```{r}
library(readr)
library(dplyr)

# ======================================
# 1. Definir versión del modelo
# ======================================
version_model <- "v1_EN_final"

# ======================================
# 2. Parámetros usados en el modelo
# ======================================
lambda_best <- 1e-04       # penalty
alpha_best  <- 0.1111111   # mixture

# Convertir valores a cadenas limpias
lambda_str <- gsub("\\.", "_", format(lambda_best, scientific = FALSE))
alpha_str  <- gsub("\\.", "_", format(alpha_best, scientific = FALSE))

# ======================================
# 3. Calcular MAE interno del modelo (en escala original)
# ======================================
pred_train_log <- predict(fit_en, train22)
pred_train_price <- exp(pred_train_log$.pred)
MAE <- mean(abs(pred_train_price - train22$price))

mae_str <- gsub("\\.", "_", format(round(MAE), scientific = FALSE))

# ======================================
# 4. Construir etiqueta de archivo FINAL
# ======================================
file_tag <- paste0(
  "ElasticNet_", version_model,
  "_lambda_", lambda_str,
  "_alpha_", alpha_str,
  "_MAE_", mae_str
)

file_name <- paste0(file_tag, ".csv")

# ======================================
# 5. Definir ruta final donde guardar
# ======================================
ruta_salida <- "../outputs/kaggle_submissions/"

# Crear si no existe
if (!dir.exists(ruta_salida)) {
  dir.create(ruta_salida, recursive = TRUE)
}

# ======================================
# 6. Construir submission final
# ======================================
submission1 <- tibble(
  property_id = test22$property_id,
  price = pred_price
)

# ======================================
# 7. Guardar archivo final COMPLETO
# ======================================
write_csv(
  submission1,
  paste0(ruta_salida, file_name)
)

# ======================================
# 8. Mensaje final
# ======================================
cat("Archivo Kaggle generado exitosamente:\n")
cat(" → ", paste0(ruta_salida, file_name), "\n")

```

# ELASTIC NET 2

Definir variable objetivo
```{r}
library(glmnet)

y_train <- train_modelo_EN$price
X_train <- train_modelo_EN %>% select(-price)
X_test  <- test_modelo_EN

```

Definir las matrices del modelo
```{r}
X_train <- train_modelo_EN %>% select(-price)
X_test  <- test_modelo_EN

X_train_mm <- model.matrix(~ ., data = X_train)[, -1]
X_test_mm  <- model.matrix(~ ., data = X_test)[, -1]

#Verificar la filas de las matrices
nrow(X_train_mm)
length(train_modelo_EN$price)

nrow(X_test_mm)
```

Entrenamiento del modelo y validación cruzada
```{r}
library(glmnet)

set.seed(123)

cv_en <- cv.glmnet(
  x = X_train_mm,
  y = train_modelo_EN$price,
  alpha = 0.5,
  nfolds = 10,
  family = "gaussian",
  standardize = TRUE
)

# Mejor lambda
cv_en$lambda.min

# Predicción en test
pred_en <- predict(cv_en, newx = X_test_mm)

# Mostrar primeros valores
head(pred_en)

```
lambda.min es el que minimiza el error de validación, según cross‐validation,
es decir, el que minimiza el error (MSE) del modelo.

Verificar predicciones internas en train
```{r}
# Predicciones internas del CV usando lambda.min
pred_cv <- predict(cv_en, newx = X_train_mm, s = "lambda.min")

# Calcular MAE
MAE <- mean(abs(pred_cv - train_modelo_EN$price))
MAE
```
```{r}
pred_en <- predict(cv_en, newx = X_test_mm, s = "lambda.min")
head(pred_en)

```


Exportar predicciones a CSV
```{r}
# ======================================
# 1. Definir versión del modelo
# ======================================
version_model <- "v2"   

# ======================================
# 2. Extraer lambda y alpha
# ======================================
lambda_best <- cv_en$lambda.min
alpha_best  <- 0.5   # valor fijo de tu modelo

# Convertir valores a cadenas seguras
lambda_str <- gsub("\\.", "_", format(round(lambda_best, 4), scientific = FALSE))
alpha_str  <- gsub("\\.", "_", format(alpha_best, scientific = FALSE))

# ======================================
# 3. Calcular MAE interno del modelo
# ======================================
pred_cv <- predict(cv_en, newx = X_train_mm, s = "lambda.min")
MAE <- mean(abs(pred_cv - train_modelo_EN$price))

# Convertir MAE a string seguro
mae_str <- gsub("\\.", "_", format(round(MAE), scientific = FALSE))

# ======================================
# 4. Construir etiqueta de archivo (sin timestamp)
# ======================================
file_tag <- paste0(
  "ElasticNet_", version_model,
  "_lambda_", lambda_str,
  "_alpha_", alpha_str,
  "_MAE_", mae_str
)

file_name <- paste0(file_tag, ".csv")

# ======================================
# 5. Definir ruta de salida (desde /notebooks/)
# ======================================
ruta_salida <- "../outputs/kaggle_submissions/"

# Crear carpeta si no existe
if (!dir.exists(ruta_salida)) {
  dir.create(ruta_salida, recursive = TRUE)
}

# ======================================
# 6. Armar submission Kaggle
# ======================================
submission2 <- data.frame(
  property_id = testEN$property_id,
  price = as.numeric(pred_en[, 1])
)

# ======================================
# 7. Guardar archivo en carpeta correcta
# ======================================
write.csv(
  submission2,
  paste0(ruta_salida, file_name),
  row.names = FALSE
)

# ======================================
# 8. Mensaje final
# ======================================
cat("Archivo Kaggle generado exitosamente en:\n")
cat(" → ", paste0(ruta_salida, file_name), "\n")

```

# ELASTIC NET 3

```{r}
library(tidymodels)
library(glmnet)

# ======================================================
# 1. Preparar datos (log del target)
# ======================================================
trainEN2 <- train_modelo_EN %>%
  mutate(price_log = log(price)) %>%
  select(-price)

# ======================================================
# 2. Recipe para Elastic Net
# ======================================================
rec_en <- recipe(price_log ~ ., data = trainEN2) %>%
  step_zv(all_predictors()) %>%
  step_nzv(all_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors())


# ======================================================
# 3. Modelo Elastic Net (tunable)
# ======================================================
mod_en <- linear_reg(
  mode = "regression",
  penalty = tune(),     # lambda
  mixture = tune()      # alpha
) %>%
  set_engine("glmnet")

# ======================================================
# 4. Workflow
# ======================================================
wf_en <- workflow() %>%
  add_recipe(rec_en) %>%
  add_model(mod_en)

# ======================================================
# 5. Grid de hiperparámetros
# ======================================================
grid_en <- grid_regular(
  penalty(range = c(-4, 0)),   # lambda: 1e-4 a 1
  mixture(range = c(0, 1)),    # alpha: 0 a 1
  levels = 6                   # 6x6 = 36 combinaciones
)

# ======================================================
# 6. Validación cruzada
# ======================================================
set.seed(123)
folds_en <- vfold_cv(trainEN2, v = 5)

# ======================================================
# 7. Entrenamiento (tuning)
# ======================================================
set.seed(123)
tuning_en <- tune_grid(
  wf_en,
  resamples = folds_en,
  grid = grid_en,
  metrics = metric_set(rmse, mae)
)

# ======================================================
# 8. Seleccionar el mejor modelo (por RMSE)
# ======================================================
best_en <- select_best(tuning_en, metric = "rmse")

best_en

```
```{r}
# 9. Modelo final con los hiperparámetros óptimos
final_en <- finalize_workflow(wf_en, best_en)

# Entrenar en todo el train
fit_en <- fit(final_en, data = trainEN2)

# ======================================================
# 10. Predecir sobre test
# ======================================================
pred_log <- predict(fit_en, test_modelo_EN)

# Volver al espacio original
pred_price <- exp(pred_log$.pred)

# Redondear
pred_price <- round(pred_price)

# Submission final
submission3 <- data.frame(
  property_id = testEN$property_id,
  price = pred_price
)

```
```{r}
# Predicciones internas del modelo final (en log)
pred_train_log <- predict(fit_en, train_modelo_EN)

# Volver al espacio original
pred_train_price <- exp(pred_train_log$.pred)

# MAE real
MAE_real <- mean(abs(pred_train_price - train_modelo_EN$price))
MAE_real

```

```{r}
# ======================================================
# 1. Versión del modelo
# ======================================================
version_model <- "v3_LOG"

# ======================================================
# 2. Ruta donde guardar archivo
# ======================================================
ruta_salida <- "../outputs/kaggle_submissions/"

# ======================================================
# 3. Extraer valores del mejor modelo
# ======================================================
lambda_best <- best_en$penalty
alpha_best  <- best_en$mixture

# Convertir a strings seguros
lambda_str <- gsub("\\.", "_", format(lambda_best, scientific = FALSE))
alpha_str  <- gsub("\\.", "_", format(alpha_best, scientific = FALSE))

# ======================================================
# 4. Convertir MAE a string seguro
# ======================================================
mae_str <- gsub("\\.", "_", format(round(MAE_real), scientific = FALSE))

# ======================================================
# 5. Construir nombre del archivo
# ======================================================
file_name <- paste0(
  "ElasticNet_", version_model,
  "_lambda_", lambda_str,
  "_alpha_", alpha_str,
  "_MAE_", mae_str,
  ".csv"
)

# ======================================================
# 6. Guardar submission
# ======================================================
write.csv(submission3, paste0(ruta_salida, file_name), row.names = FALSE)

# ======================================================
# 7. Confirmación
# ======================================================
cat("Archivo guardado exitosamente:\n")
cat("→ ", paste0(ruta_salida, file_name), "\n")

```

# ELASTIC NET 4
```{r}
library(tidymodels)
library(glmnet)

# ======================================================
# 1. Preparar datos: crear log del precio
# ======================================================
trainEN2 <- train_modelo_EN %>%
  mutate(price_log = log(price)) %>%
  select(-price)

testEN2 <- test_modelo_EN   # test sin la variable price_log


# ======================================================
# 2. Recipe para Elastic Net (NO usa price_log como predictor)
# ======================================================
rec_en <- recipe(price_log ~ ., data = trainEN2) %>%
  step_zv(all_predictors()) %>%
  step_nzv(all_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors())


# ======================================================
# 3. Modelo Elastic Net 
# ======================================================
mod_en <- linear_reg(
  mode = "regression",
  penalty = tune(),
  mixture = tune()
) %>% 
  set_engine("glmnet")


# ======================================================
# 4. Workflow
# ======================================================
wf_en <- workflow() %>%
  add_recipe(rec_en) %>%
  add_model(mod_en)


# ======================================================
# 5. Grid de hiperparámetros
# ======================================================
grid_en <- grid_regular(
  penalty(range = c(-4, 0)),   # λ: 1e-4 a 1
  mixture(range = c(0, 1)),    # α: 0 a 1
  levels = 6
)


# ======================================================
# 6. Validación cruzada
# ======================================================
set.seed(123)
folds_en <- vfold_cv(trainEN2, v = 5)


# ======================================================
# 7. Entrenamiento (tuning)
# ======================================================
set.seed(123)
tuning_en <- tune_grid(
  wf_en,
  resamples = folds_en,
  grid = grid_en,
  metrics = metric_set(rmse, mae)
)


# ======================================================
# 8. Seleccionar mejor modelo
# ======================================================
best_en <- select_best(tuning_en, metric = "rmse")
best_en


# ======================================================
# 9. Entrenar modelo final con todos los datos
# ======================================================
final_en <- finalize_workflow(wf_en, best_en)

fit_en <- fit(final_en, data = trainEN2)


# ======================================================
# 10. Predicción sobre TEST
# ======================================================
pred_log <- predict(fit_en, testEN2)

pred_price <- exp(pred_log$.pred)
pred_price <- round(pred_price)


# ======================================================
# 11. Crear submission Kaggle
# ======================================================
submission4 <- data.frame(
  property_id = testEN$property_id,
  price = pred_price
)


# ======================================================
# 12. MAE interno del modelo final (en train)
# ======================================================
pred_train_log <- predict(fit_en, trainEN2)
pred_train_price <- exp(pred_train_log$.pred)

MAE_real <- mean(abs(pred_train_price - train_modelo_EN$price))
MAE_real

```

```{r}
# ======================================================
# GUARDAR SUBMISSION EN LA CARPETA DEL PROYECTO
# ======================================================

# Ruta donde quieres guardar el archivo
ruta_salida <- "../outputs/kaggle_submissions/"

# Crear nombre del archivo usando métricas reales
file_name <- paste0(
  "ElasticNet_v4_LOG_lambda_", gsub("\\.", "_", best_en$penalty),
  "_alpha_", gsub("\\.", "_", best_en$mixture),
  "_MAE_", format(round(MAE_real), scientific = FALSE),
  ".csv"
)

# Guardar
write.csv(submission4, paste0(ruta_salida, file_name), row.names = FALSE)

cat("Archivo guardado exitosamente en:\n")
cat(paste0(ruta_salida, file_name), "\n")

```

# ELASTIC NET 5

```{r}
message("Cargando los dataframes finales procesados...")
train_full <- readRDS(here::here("data", "processed", "train_final.rds"))
test_full  <- readRDS(here::here("data", "processed", "test_final.rds"))
message("Datos finales cargados.")

# -- CREAR LA VARIABLE OBJETIVO CORRECTA: log(price) --
train_full <- train_full %>% mutate(log_price = log1p(price))

# -- Limpieza de Outliers en Precio --
q_low  <- quantile(train_full$log_price, 0.01, na.rm = TRUE)
q_high <- quantile(train_full$log_price, 0.99, na.rm = TRUE)
train_full <- train_full %>% filter(log_price >= q_low & log_price <= q_high)
```

DIVISIÓN ESPACIAL: TRAIN vs. PRUEBA

```{r}
message("\nDividiendo los datos")

train <- train_full

# El conjunto real para submission
test_submission <- test_full

message(paste("Tamaño del set de entrenamiento:", nrow(train)))
```

DEFINICIÓN DE RECETAS

```{r}
message("\nDefiniendo recetas de preprocesamiento...")

has_vars <- names(dplyr::select(train, starts_with("has_")))

features <- c(
  "surface_total", "surface_covered", "bedrooms", "bathrooms", "estrato",
  "dist_parques", "dist_colegios", "dist_restaurantes",
  "latitude", "longitude",
  "property_type",
  has_vars
)

model_formula <- as.formula(paste("log_price ~", paste(features, collapse = " + ")))

# -- Receta 1 --
rec_1 <- recipe(model_formula, data = train) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_interact(terms = ~ surface_total:estrato + surface_covered:estrato) %>%
  step_zv(all_predictors()) %>%
  step_center(all_numeric_predictors()) %>%
  step_scale(all_numeric_predictors())

# -- Receta 2 --
rec_2 <- recipe(model_formula, data = train) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_interact(terms = ~ surface_total:estrato + surface_covered:estrato) %>%
  step_poly(dist_parques, dist_colegios, dist_restaurantes, degree = 2) %>%
  step_zv(all_predictors()) %>%
  step_center(all_numeric_predictors()) %>%
  step_scale(all_numeric_predictors())

message("Dos recetas creadas.")
```

ESPECIFICACIÓN DEL MODELO Y TUNING GRID

```{r}
elastic_net_spec <- linear_reg(
  penalty = tune(),
  mixture = tune()
) %>% set_engine("glmnet")

set.seed(123)
tuning_grid <- grid_regular(
  penalty(range = c(-4, 0)),
  mixture(range = c(0, 1)),
  levels = 5
)

set.seed(456)
cv_folds <- vfold_cv(train, v = 5)

```

WORKFLOWS Y TUNING

```{r}
workflow_1 <- workflow() %>% add_recipe(rec_1) %>% add_model(elastic_net_spec)
workflow_2 <- workflow() %>% add_recipe(rec_2) %>% add_model(elastic_net_spec)

message("\nIniciando tuning para Workflow 1...")
tune_res1 <- tune_grid(
  workflow_1,
  resamples = cv_folds,
  grid = tuning_grid,
  metrics = metric_set(yardstick::rmse, yardstick::mae, yardstick::rsq)
)
message("Tuning para Workflow 1 completado.")

message("\nIniciando tuning para Workflow 2...")
tune_res2 <- tune_grid(
  workflow_2,
  resamples = cv_folds,
  grid = tuning_grid,
  metrics = metric_set(yardstick::rmse, yardstick::mae, yardstick::rsq)
)
message("Tuning para Workflow 2 completado.")

```

SELECCIÓN DE MEJORES PARÁMETROS

```{r}
message("\n--- Resultados del Tuning ---")

message("\n-- Workflow 1 (Base) --")
show_best(tune_res1, metric = "rmse")

message("\n-- Workflow 2 (Polinómico) --")
show_best(tune_res2, metric = "rmse")

best_params_1 <- select_best(tune_res1, metric = "rmse")
best_params_2 <- select_best(tune_res2, metric = "rmse")

print(best_params_1)
print(best_params_2)

```



```{r}
tidymodels::tidymodels_prefer()

model_final_1 <- linear_reg(
  penalty = best_params_1$penalty,
  mixture = best_params_1$mixture
) %>% set_engine("glmnet")

model_final_2 <- linear_reg(
  penalty = best_params_2$penalty,
  mixture = best_params_2$mixture
) %>% set_engine("glmnet")

final_workflow_1 <- workflow() %>% add_recipe(rec_1) %>% add_model(model_final_1)
final_workflow_2 <- workflow() %>% add_recipe(rec_2) %>% add_model(model_final_2)

```

ENTRENAMIENTO FINAL

```{r}
message("\n=== Entrenando Modelos Finales ===")

fit_final_1 <- fit(final_workflow_1, data = train)
fit_final_2 <- fit(final_workflow_2, data = train)

message("Modelos finales entrenados correctamente.")

```


MÉTRICAS SOBRE TRAIN

```{r}
pred_train_1 <- predict(fit_final_1, train)$.pred
pred_train_2 <- predict(fit_final_2, train)$.pred

train_results <- tibble(
  real = train$log_price,
  pred_1 = pred_train_1,
  pred_2 = pred_train_2
)

message("\n=== Métricas ===")
metricas_1 <- metrics(train_results, truth = real, estimate = pred_1)
metricas_2 <- metrics(train_results, truth = real, estimate = pred_2)

print(metricas_1)
print(metricas_2)

```

SELECCIÓN DEL MEJOR MODELO

```{r}
# Usamos RMSE de train para decidir
if (metricas_1$.estimate[metricas_1$.metric == "rmse"] <
    metricas_2$.estimate[metricas_2$.metric == "rmse"]) {
  
  best_fit <- fit_final_1
  message("\nEl Workflow 1 fue el mejor.")
  
} else {
  best_fit <- fit_final_2
  message("\nEl Workflow 2 fue el mejor.")
}

```

PREDICCIÓN FINAL 

```{r}
message("\nGenerando predicciones para Submission...")

predictions_kaggle <- predict(best_fit, test_submission)$.pred
price_final <- expm1(predictions_kaggle)

submission <- tibble(
  property_id = test_submission$property_id,
  price = round(price_final)
)

ruta_destino <- here::here("outputs", "kaggle_submissions")
dir.create(ruta_destino, showWarnings = FALSE, recursive = TRUE)

ruta_archivo <- here::here(ruta_destino, "ElasticNet_v5.csv")
write_csv(submission, ruta_archivo)

message("\nArchivo guardado en:")
message(ruta_archivo)

summary(submission$price)

```

# ELASTIC NET 6

```{r}
# ================================
# 1. PREPARAR DATASETS BASE
# ================================

train_modelo_EN6 <- trainEN %>% 
  select(-property_id, -title, -description, -city, -operation_type,
         -has_pisos_vivienda, -has_cocina_integral, -has_salon_social, -barrio)

test_modelo_EN6 <- testEN %>% 
  select(-property_id, -title, -description, -city, -operation_type,
         -has_pisos_vivienda, -has_cocina_integral, -has_salon_social, -barrio, -price)
```



```{r}
# ============================================================
#     ELASTIC NET + VALIDACIÓN CRUZADA ESPACIAL (CLUSTERING)
# ============================================================

library(sf)
library(glmnet)
library(dplyr)
library(tibble)
library(readr)

set.seed(123)

# ============================================================
# 1. CREAR OBJETO ESPACIAL PARA CLUSTERING
# ============================================================

train_sf <- st_as_sf(
  train_modelo_EN6,
  coords = c("longitude", "latitude"),
  crs = 4326
)

train_sf <- st_transform(train_sf, 3116)

coords <- st_coordinates(train_sf)

# ============================================================
# 2. CLUSTERING ESPACIAL (REEMPLAZA blockCV)
# ============================================================

k <- 5
km <- kmeans(coords, centers = k)

train_sf$fold_id <- km$cluster

folds <- vector("list", k)
for (i in 1:k) {
  folds[[i]] <- list(
    train = which(train_sf$fold_id != i),
    test  = which(train_sf$fold_id == i)
  )
}

cat("===== Observaciones por Fold =====\n")
print(table(train_sf$fold_id))

# ============================================================
# 3. MATRICES PARA GLMNET (ROBUSTAS: TRAIN & TEST IGUALES)
# ============================================================

# Fórmula SOLO CON PREDICTORES (sin price)
preds <- colnames(train_modelo_EN6)[colnames(train_modelo_EN6) != "price"]
form <- as.formula(paste("~", paste(preds, collapse = " + ")))

# ---- TRAIN ----
mf_train <- model.frame(form, data = train_modelo_EN6)
X <- model.matrix(form, data = mf_train)
y <- train_modelo_EN6$price

# ---- TEST ----
mf_test <- model.frame(form, data = test_modelo_EN6,
                       xlev = lapply(mf_train, levels))

X_test <- model.matrix(form, data = mf_test)

# EMPAREJAR COLUMNAS ENTRE TRAIN Y TEST
missing_cols <- setdiff(colnames(X), colnames(X_test))
extra_cols   <- setdiff(colnames(X_test), colnames(X))

# agregar columnas faltantes
if (length(missing_cols) > 0) {
  X_test <- cbind(
    X_test,
    matrix(0, nrow(X_test), length(missing_cols),
           dimnames = list(NULL, missing_cols))
  )
}

# quitar columnas extra
if (length(extra_cols) > 0) {
  X_test <- X_test[, colnames(X_test) %in% colnames(X)]
}

# reordenar columnas
X_test <- X_test[, colnames(X)]

# ============================================================
# 4. FUNCIÓN MAE PARA VALIDACIÓN CRUZADA ESPACIAL
# ============================================================

MAE_lambda <- function(lambda_value) {
  maes <- c()
  
  for (fold in folds) {
    idx_train <- fold$train
    idx_test  <- fold$test
    
    fit <- glmnet(
      x = X[idx_train, ],
      y = y[idx_train],
      alpha = 0.5,
      lambda = lambda_value,
      standardize = TRUE
    )
    
    pred <- predict(fit, newx = X[idx_test, ])
    maes <- c(maes, mean(abs(pred - y[idx_test])))
  }
  
  mean(maes)
}

# ============================================================
# 5. BUSCAR EL MEJOR LAMBDA (SPATIAL CV)
# ============================================================

lambda_grid <- 10^seq(-3, 0, length.out = 30)

mae_results <- sapply(lambda_grid, MAE_lambda)

best_lambda <- lambda_grid[which.min(mae_results)]

cat("\n==============================\n")
cat("Mejor lambda:", best_lambda, "\n")
cat("MAE:", min(mae_results), "\n")
cat("==============================\n")

# ============================================================
# 6. ENTRENAMIENTO FINAL COMPLETO
# ============================================================

final_en <- glmnet(
  x = X,
  y = y,
  alpha = 0.5,
  lambda = best_lambda,
  standardize = TRUE
)

# ============================================================
# 7. PREDICCIÓN FINAL SOBRE TEST
# ============================================================

pred_test <- as.numeric(predict(final_en, newx = X_test))

submission6 <- tibble(
  property_id = testEN$property_id,
  price = pred_test
)

```

```{r}
# ======================================================
# GUARDAR SUBMISSION EN LA CARPETA DEL PROYECTO (V6)
# ======================================================

# Carpeta de salida
ruta_salida <- "../outputs/kaggle_submissions/"

# Asegurar que la carpeta exista
if (!dir.exists(ruta_salida)) {
    dir.create(ruta_salida, recursive = TRUE)
}

# =============================
#  NOMBRE DEL ARCHIVO - V6
# =============================

# Convertir valores numéricos a formato para nombres de archivo
lambda_str <- gsub("\\.", "_", best_lambda)
mae_str    <- gsub("\\.", "_", format(round(min(mae_results), 4), scientific = FALSE))

file_name <- paste0(
  "ElasticNet_V6_SpatialCV_",
  "lambda_", lambda_str,
  "_alpha_0_5_",
  "MAE_", mae_str,
  ".csv"
)

# =============================
#  GUARDAR ARCHIVO
# =============================

write.csv(
    submission6,
    paste0(ruta_salida, file_name),
    row.names = FALSE
)

cat("Archivo guardado exitosamente en:\n")
cat(paste0(ruta_salida, file_name), "\n")

```

